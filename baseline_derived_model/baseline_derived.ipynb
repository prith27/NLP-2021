{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_derived.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dO4AnDMk3lw"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw1iJHPvksdp",
        "outputId": "61ac1484-2968-40da-de6f-3071c1bf8290"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt7FSxrpk7zv",
        "outputId": "b0b8f296-38e1-4912-e64a-935728c99480"
      },
      "source": [
        "% cd /content/drive/MyDrive/Colab Notebooks/ICHCL_baseline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ICHCL_baseline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdYaBhtnlFW7"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgZeIV6wk-HM",
        "outputId": "abc4fc78-d407-4d39-c366-63b008561fea"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import re\n",
        "import json\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import stemmer as hindi_stemmer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ5-HqwOlLfe"
      },
      "source": [
        "## Initializing Stopwords and Stemmers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f6GCL6ulJlR"
      },
      "source": [
        "english_stopwords = stopwords.words(\"english\")\n",
        "with open('final_stopwords.txt', encoding = 'utf-8') as f:\n",
        "    hindi_stopwords = f.readlines()\n",
        "    for i in range(len(hindi_stopwords)):\n",
        "        hindi_stopwords[i] = re.sub('\\n','',hindi_stopwords[i])\n",
        "stopwords = english_stopwords + hindi_stopwords\n",
        "english_stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWah1mfolRsM"
      },
      "source": [
        "## Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcWiMTCNlP0_"
      },
      "source": [
        "train_directories = []\n",
        "for i in glob(\"data/train/*/\"):\n",
        "    for j in glob(i+'*/'):\n",
        "        train_directories.append(j)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq28ZQeylVTl"
      },
      "source": [
        "data = []\n",
        "for i in train_directories:\n",
        "    with open(i+'data.json', encoding='utf-8') as f:\n",
        "        data.append(json.load(f))\n",
        "labels = []\n",
        "for i in train_directories:\n",
        "    with open(i+'labels.json', encoding='utf-8') as f:\n",
        "        labels.append(json.load(f))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV_ti_NslXWB"
      },
      "source": [
        "def tr_flatten(d,l):\n",
        "    flat_text = []\n",
        "    flat_text.append({\n",
        "        'tweet_id':d['tweet_id'],\n",
        "        'text':d['tweet'],\n",
        "        'label':l[d['tweet_id']]\n",
        "    })\n",
        "\n",
        "    for i in d['comments']:\n",
        "            flat_text.append({\n",
        "                'tweet_id':i['tweet_id'],\n",
        "                'text':flat_text[0]['text'] +' '+i['tweet'], #flattening comments(appending one after the other)\n",
        "                'label':l[i['tweet_id']]\n",
        "            })\n",
        "            if 'replies' in i.keys():\n",
        "                for j in i['replies']:\n",
        "                    flat_text.append({\n",
        "                        'tweet_id':j['tweet_id'],\n",
        "                        'text':flat_text[0]['text'] +' '+ i['tweet'] +' '+ j['tweet'], #flattening replies\n",
        "                        'label':l[j['tweet_id']]\n",
        "                    })\n",
        "    return flat_text\n",
        "\n",
        "def te_flatten(d):\n",
        "    flat_text = []\n",
        "    flat_text.append({\n",
        "        'tweet_id':d['tweet_id'],\n",
        "        'text':d['tweet'],\n",
        "    })\n",
        "\n",
        "    for i in d['comments']:\n",
        "            flat_text.append({\n",
        "                'tweet_id':i['tweet_id'],\n",
        "                'text':flat_text[0]['text'] + i['tweet'],\n",
        "            })\n",
        "            if 'replies' in i.keys():\n",
        "                for j in i['replies']:\n",
        "                    flat_text.append({\n",
        "                        'tweet_id':j['tweet_id'],\n",
        "                        'text':flat_text[0]['text'] + i['tweet'] + j['tweet'],\n",
        "                    })\n",
        "    return flat_text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcXTLbKClZO-"
      },
      "source": [
        "data_label = []\n",
        "#for train\n",
        "for i in range(len(labels)):\n",
        "    for j in tr_flatten(data[i], labels[i]):\n",
        "        data_label.append(j)\n",
        "train_len = len(data_label)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbGtJU60lcVS"
      },
      "source": [
        "df = pd.DataFrame(data_label, columns = data_label[0].keys(), index = None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OrX2FTOlemq"
      },
      "source": [
        "tweets = df.text\n",
        "y = df.label"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sood4Gtll7V1"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhUc8gLyl2vx"
      },
      "source": [
        "regex_for_english_hindi_emojis=\"[^a-zA-Z#\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF\\u0900-\\u097F]\"\n",
        "def clean_tweet(tweet):\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\",' ', tweet)\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\",' ', tweet)\n",
        "    tweet = re.sub(regex_for_english_hindi_emojis,' ', tweet)\n",
        "    tweet = re.sub(\"RT \", \" \", tweet)\n",
        "    tweet = re.sub(\"\\n\", \" \", tweet)\n",
        "    tweet = re.sub(r\" +\", \" \", tweet)\n",
        "    tokens = []\n",
        "    for token in tweet.split():\n",
        "        if token not in stopwords:\n",
        "            token = english_stemmer.stem(token)\n",
        "            token = hindi_stemmer.hi_stem(token)\n",
        "            tokens.append(token)\n",
        "    return \" \".join(tokens)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB6NMo01mEdj"
      },
      "source": [
        "cleaned_tweets = [clean_tweet(tweet) for tweet in tweets]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwnWHEK5mASR"
      },
      "source": [
        "## Featuring Raw Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye0RQhddl_m4"
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df = 5)\n",
        "X = vectorizer.fit_transform(cleaned_tweets)\n",
        "X = X.todense()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH7OPHyamKMM"
      },
      "source": [
        "## Test Train Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntM-5lbFmIPx"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysFiukIDmOSl"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnrXyVz4mNiW",
        "outputId": "2bc6f2f0-d57c-4db3-f235-f9944d5ff528"
      },
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYBU3pHzmU8Z",
        "outputId": "084d9d9f-0cbc-4904-c5e3-02e45a17fe3b"
      },
      "source": [
        "y_pred = classifier.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         HOF       0.72      0.72      0.72       566\n",
            "        NONE       0.73      0.73      0.73       582\n",
            "\n",
            "    accuracy                           0.73      1148\n",
            "   macro avg       0.73      0.73      0.73      1148\n",
            "weighted avg       0.73      0.73      0.73      1148\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-FAXsngpbgD"
      },
      "source": [
        "## Ensembling-Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Yf1269pdYv"
      },
      "source": [
        "# Importing Libraries\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nryamv0mp4vu"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_pred = lr.predict(X_val)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URkjY4jAp-Bv"
      },
      "source": [
        "# Support Vector Machine\n",
        "\n",
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)\n",
        "svc_pred = svc.predict(X_val)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpQF9oJ3qAir"
      },
      "source": [
        "# Naive Bayes\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "nb_pred = nb.predict(X_val)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrrZkSk4qED_"
      },
      "source": [
        "# Stochastic Gradient Descent\n",
        "\n",
        "sgd = SGDClassifier()\n",
        "sgd.fit(X_train, y_train)\n",
        "sgd_pred = sgd.predict(X_val)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qym41mrJqGcq"
      },
      "source": [
        "# K Nearest Neighbour\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_val)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSowJYh1qKpl"
      },
      "source": [
        "# Decision Tree\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_val)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1oWbxQVqMsU"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_val)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHB6p-auqOsB"
      },
      "source": [
        "# Voting\n",
        "\n",
        "y_pred = []\n",
        "\n",
        "for i in range(len(lr_pred)):\n",
        "    one = 0\n",
        "    zero = 0\n",
        "    predictions = [lr_pred[i], svc_pred[i], nb_pred[i], sgd_pred[i], knn_pred[i], dt_pred[i], rf_pred[i]]\n",
        "    # predictions = [lr_pred[i], nb_pred[i], sgd_pred[i], dt_pred[i], rf_pred[i]]\n",
        "    for pred in predictions:\n",
        "        if pred == 'HOF': one += 1\n",
        "        if pred == 'NONE': zero +=1\n",
        "    if one > zero: y_pred.append('HOF')\n",
        "    else: y_pred.append('NONE')\n",
        "\n",
        "y_pred = np.array(y_pred)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3Mh7xT1qWYV",
        "outputId": "b293d435-6672-4ee3-e02f-65469e24985f"
      },
      "source": [
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         HOF       0.73      0.71      0.72       566\n",
            "        NONE       0.72      0.74      0.73       582\n",
            "\n",
            "    accuracy                           0.72      1148\n",
            "   macro avg       0.72      0.72      0.72      1148\n",
            "weighted avg       0.72      0.72      0.72      1148\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNw8SP39mboR"
      },
      "source": [
        "## Neural Network 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybGRZR5cmYn1"
      },
      "source": [
        "le = LabelEncoder() #label encoding labels for training Dense Neural Network\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_val = le.transform(y_val)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gMEyyTRmfN9"
      },
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        Dense(32, activation=\"relu\"),\n",
        "        Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.compile('adam', loss='binary_crossentropy', metrics = ['accuracy']) #compiling a neural network with 3 layers for classification"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtKZA3-omiX0",
        "outputId": "6e278275-e53a-4521-8d1c-c922d6ece8cb"
      },
      "source": [
        "model.fit(X_train, y_train, epochs = 5, batch_size = 32)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.6338 - accuracy: 0.6616\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 3ms/step - loss: 0.5286 - accuracy: 0.7409\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7979\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8314\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.8574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf031fc890>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7Ggqm7Dmj9Y"
      },
      "source": [
        "y_pred = model.predict(X_val)\n",
        "y_pred = (y_pred > 0.5).astype('int64')\n",
        "y_pred = y_pred.reshape(len(y_pred))    "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiNHWuKBmmNw",
        "outputId": "609ec47b-1aaa-4082-9837-63bb79f23302"
      },
      "source": [
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.70      0.70       566\n",
            "           1       0.71      0.72      0.71       582\n",
            "\n",
            "    accuracy                           0.71      1148\n",
            "   macro avg       0.71      0.71      0.71      1148\n",
            "weighted avg       0.71      0.71      0.71      1148\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gqp7UgQrTRm"
      },
      "source": [
        "## Neural Network 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBySkgmKr_oe"
      },
      "source": [
        "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(MyThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        val_acc = logs[\"val_accuracy\"]\n",
        "        if val_acc >= self.threshold:\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvg2EegbsOpm"
      },
      "source": [
        "callback = MyThresholdCallback(threshold=0.73)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbdxav0rrWla"
      },
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        Dropout(0.8),\n",
        "        Dense(32, activation=\"relu\"),\n",
        "        Dropout(0.6),\n",
        "        Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.compile('adam', loss='binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nFB7UACrbyC",
        "outputId": "0c6daf8c-7e18-43f7-ed9b-ea959776232b"
      },
      "source": [
        "model.fit(X_train, y_train, epochs = 1000, batch_size = 64, validation_data=(X_val, y_val), callbacks=[callback])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.6909 - accuracy: 0.5348 - val_loss: 0.6842 - val_accuracy: 0.6629\n",
            "Epoch 2/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6755 - accuracy: 0.5971 - val_loss: 0.6540 - val_accuracy: 0.6855\n",
            "Epoch 3/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6455 - accuracy: 0.6435 - val_loss: 0.6129 - val_accuracy: 0.7073\n",
            "Epoch 4/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6129 - accuracy: 0.6842 - val_loss: 0.5884 - val_accuracy: 0.7082\n",
            "Epoch 5/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5908 - accuracy: 0.7067 - val_loss: 0.5783 - val_accuracy: 0.7134\n",
            "Epoch 6/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5811 - accuracy: 0.7149 - val_loss: 0.5737 - val_accuracy: 0.7178\n",
            "Epoch 7/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5699 - accuracy: 0.7289 - val_loss: 0.5690 - val_accuracy: 0.7221\n",
            "Epoch 8/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5511 - accuracy: 0.7450 - val_loss: 0.5645 - val_accuracy: 0.7265\n",
            "Epoch 9/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5341 - accuracy: 0.7622 - val_loss: 0.5606 - val_accuracy: 0.7317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdee3e5b990>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pca4wKirfmn"
      },
      "source": [
        "y_pred = model.predict(X_val)\n",
        "y_pred = (y_pred > 0.5).astype('int64')\n",
        "y_pred = y_pred.reshape(len(y_pred))"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A1Sh7v-rhQl",
        "outputId": "04309272-9ed3-4e01-ec68-34749180ddae"
      },
      "source": [
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.74      0.73       566\n",
            "           1       0.74      0.72      0.73       582\n",
            "\n",
            "    accuracy                           0.73      1148\n",
            "   macro avg       0.73      0.73      0.73      1148\n",
            "weighted avg       0.73      0.73      0.73      1148\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RboNaXOU3-lQ"
      },
      "source": [
        "## Neural Network 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6rPVYmb4D7A"
      },
      "source": [
        "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(MyThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        val_acc = logs[\"val_accuracy\"]\n",
        "        if val_acc >= self.threshold:\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWWeg2Sh4Fw9"
      },
      "source": [
        "callback = MyThresholdCallback(threshold=0.74)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znfgLR6M4Hzr"
      },
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        Dense(32, activation=\"relu\"),\n",
        "        Dropout(0.8),\n",
        "        Dense(16, activation=\"relu\"),\n",
        "        Dropout(0.6),\n",
        "        Dense(8, activation=\"sigmoid\"),\n",
        "        Dropout(0.4),\n",
        "        Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.compile('adam', loss='binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE-qV2dM4JuZ",
        "outputId": "9ae42431-a65f-49fe-e91b-a4cac8c15a9e"
      },
      "source": [
        "model.fit(X_train, y_train, epochs = 1000, batch_size = 64, validation_data=(X_val, y_val), callbacks=[callback])"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "72/72 [==============================] - 59s 7ms/step - loss: 0.7131 - accuracy: 0.5148 - val_loss: 0.6921 - val_accuracy: 0.4948\n",
            "Epoch 2/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.7094 - accuracy: 0.5137 - val_loss: 0.6882 - val_accuracy: 0.5923\n",
            "Epoch 3/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.7049 - accuracy: 0.5139 - val_loss: 0.6823 - val_accuracy: 0.6707\n",
            "Epoch 4/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6990 - accuracy: 0.5233 - val_loss: 0.6729 - val_accuracy: 0.6794\n",
            "Epoch 5/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6858 - accuracy: 0.5544 - val_loss: 0.6587 - val_accuracy: 0.6890\n",
            "Epoch 6/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6667 - accuracy: 0.5899 - val_loss: 0.6393 - val_accuracy: 0.6986\n",
            "Epoch 7/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.6093 - val_loss: 0.6208 - val_accuracy: 0.7099\n",
            "Epoch 8/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6497 - accuracy: 0.6193 - val_loss: 0.6083 - val_accuracy: 0.7134\n",
            "Epoch 9/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.6389 - val_loss: 0.5969 - val_accuracy: 0.7169\n",
            "Epoch 10/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6271 - accuracy: 0.6588 - val_loss: 0.5886 - val_accuracy: 0.7134\n",
            "Epoch 11/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6067 - accuracy: 0.6742 - val_loss: 0.5806 - val_accuracy: 0.7143\n",
            "Epoch 12/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6118 - accuracy: 0.6786 - val_loss: 0.5763 - val_accuracy: 0.7134\n",
            "Epoch 13/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5907 - accuracy: 0.7010 - val_loss: 0.5722 - val_accuracy: 0.7178\n",
            "Epoch 14/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5847 - accuracy: 0.7043 - val_loss: 0.5695 - val_accuracy: 0.7195\n",
            "Epoch 15/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5777 - accuracy: 0.7123 - val_loss: 0.5667 - val_accuracy: 0.7186\n",
            "Epoch 16/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.7287 - val_loss: 0.5637 - val_accuracy: 0.7221\n",
            "Epoch 17/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5638 - accuracy: 0.7180 - val_loss: 0.5629 - val_accuracy: 0.7308\n",
            "Epoch 18/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5528 - accuracy: 0.7345 - val_loss: 0.5602 - val_accuracy: 0.7247\n",
            "Epoch 19/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7378 - val_loss: 0.5579 - val_accuracy: 0.7239\n",
            "Epoch 20/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5478 - accuracy: 0.7419 - val_loss: 0.5596 - val_accuracy: 0.7282\n",
            "Epoch 21/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7585 - val_loss: 0.5588 - val_accuracy: 0.7274\n",
            "Epoch 22/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7600 - val_loss: 0.5576 - val_accuracy: 0.7291\n",
            "Epoch 23/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5202 - accuracy: 0.7589 - val_loss: 0.5515 - val_accuracy: 0.7413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdef8a9e350>"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxReSxHz4L8M"
      },
      "source": [
        "y_pred = model.predict(X_val)\n",
        "y_pred = (y_pred > 0.5).astype('int64')\n",
        "y_pred = y_pred.reshape(len(y_pred))"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyekrsZP4Nra",
        "outputId": "25007a98-e319-456d-e7a4-ac47d117684a"
      },
      "source": [
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.72      0.73       566\n",
            "           1       0.73      0.77      0.75       582\n",
            "\n",
            "    accuracy                           0.74      1148\n",
            "   macro avg       0.74      0.74      0.74      1148\n",
            "weighted avg       0.74      0.74      0.74      1148\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJMvdsO9Hjd-",
        "outputId": "547a5f67-1548-4257-d97b-31cd75ce1c51"
      },
      "source": [
        "model.save('saved_models/nn_3')"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_models/nn_3/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zliAKtIE7kqB"
      },
      "source": [
        "## Neural Network 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lva3rtPr7o29"
      },
      "source": [
        "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(MyThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        val_acc = logs[\"val_accuracy\"]\n",
        "        if val_acc >= self.threshold:\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZJuPUY-7qvo"
      },
      "source": [
        "callback = MyThresholdCallback(threshold=0.75)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG2RVz3t7uAE"
      },
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        Dense(32, activation=\"relu\"),\n",
        "        Dropout(0.8),\n",
        "        BatchNormalization(),\n",
        "        Dense(32, activation=\"relu\"),\n",
        "        Dropout(0.8),\n",
        "        Dense(16, activation=\"relu\"),\n",
        "        Dropout(0.6),\n",
        "        Dense(8, activation=\"sigmoid\"),\n",
        "        Dropout(0.4),\n",
        "        Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.compile('adam', loss='binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUexpCKU7wRl",
        "outputId": "61143b21-c3cd-4b9d-ea28-0073e740c3f5"
      },
      "source": [
        "model.fit(X_train, y_train, epochs = 1000, batch_size = 64, validation_data=(X_val, y_val), callbacks=[callback])"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "72/72 [==============================] - 2s 8ms/step - loss: 0.8438 - accuracy: 0.5037 - val_loss: 0.7679 - val_accuracy: 0.5070\n",
            "Epoch 2/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.7546 - accuracy: 0.5002 - val_loss: 0.7225 - val_accuracy: 0.5070\n",
            "Epoch 3/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.7232 - accuracy: 0.4961 - val_loss: 0.7024 - val_accuracy: 0.5070\n",
            "Epoch 4/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.7114 - accuracy: 0.4952 - val_loss: 0.6955 - val_accuracy: 0.5070\n",
            "Epoch 5/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.7093 - accuracy: 0.4950 - val_loss: 0.6921 - val_accuracy: 0.5070\n",
            "Epoch 6/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.7000 - accuracy: 0.5107 - val_loss: 0.6898 - val_accuracy: 0.5183\n",
            "Epoch 7/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.7068 - accuracy: 0.4922 - val_loss: 0.6885 - val_accuracy: 0.5523\n",
            "Epoch 8/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.7000 - accuracy: 0.5094 - val_loss: 0.6875 - val_accuracy: 0.6028\n",
            "Epoch 9/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6980 - accuracy: 0.5174 - val_loss: 0.6872 - val_accuracy: 0.6237\n",
            "Epoch 10/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6981 - accuracy: 0.5122 - val_loss: 0.6864 - val_accuracy: 0.6315\n",
            "Epoch 11/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6993 - accuracy: 0.5033 - val_loss: 0.6863 - val_accuracy: 0.6098\n",
            "Epoch 12/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6957 - accuracy: 0.5118 - val_loss: 0.6851 - val_accuracy: 0.6211\n",
            "Epoch 13/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6967 - accuracy: 0.5022 - val_loss: 0.6843 - val_accuracy: 0.6115\n",
            "Epoch 14/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.5144 - val_loss: 0.6841 - val_accuracy: 0.6263\n",
            "Epoch 15/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6956 - accuracy: 0.5048 - val_loss: 0.6837 - val_accuracy: 0.6185\n",
            "Epoch 16/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5172 - val_loss: 0.6829 - val_accuracy: 0.6298\n",
            "Epoch 17/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5122 - val_loss: 0.6815 - val_accuracy: 0.6237\n",
            "Epoch 18/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5083 - val_loss: 0.6802 - val_accuracy: 0.6280\n",
            "Epoch 19/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.5216 - val_loss: 0.6780 - val_accuracy: 0.6385\n",
            "Epoch 20/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.5296 - val_loss: 0.6748 - val_accuracy: 0.6507\n",
            "Epoch 21/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6889 - accuracy: 0.5335 - val_loss: 0.6716 - val_accuracy: 0.6577\n",
            "Epoch 22/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6882 - accuracy: 0.5346 - val_loss: 0.6700 - val_accuracy: 0.6516\n",
            "Epoch 23/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6879 - accuracy: 0.5401 - val_loss: 0.6666 - val_accuracy: 0.6551\n",
            "Epoch 24/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6878 - accuracy: 0.5364 - val_loss: 0.6649 - val_accuracy: 0.6507\n",
            "Epoch 25/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6845 - accuracy: 0.5459 - val_loss: 0.6608 - val_accuracy: 0.6594\n",
            "Epoch 26/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.5651 - val_loss: 0.6583 - val_accuracy: 0.6472\n",
            "Epoch 27/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6809 - accuracy: 0.5653 - val_loss: 0.6549 - val_accuracy: 0.6498\n",
            "Epoch 28/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6743 - accuracy: 0.5712 - val_loss: 0.6483 - val_accuracy: 0.6611\n",
            "Epoch 29/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6724 - accuracy: 0.5721 - val_loss: 0.6416 - val_accuracy: 0.6681\n",
            "Epoch 30/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6676 - accuracy: 0.5908 - val_loss: 0.6367 - val_accuracy: 0.6716\n",
            "Epoch 31/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6585 - accuracy: 0.6087 - val_loss: 0.6294 - val_accuracy: 0.6751\n",
            "Epoch 32/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6596 - accuracy: 0.6082 - val_loss: 0.6270 - val_accuracy: 0.6777\n",
            "Epoch 33/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6525 - accuracy: 0.6167 - val_loss: 0.6239 - val_accuracy: 0.6620\n",
            "Epoch 34/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6493 - accuracy: 0.6237 - val_loss: 0.6138 - val_accuracy: 0.6882\n",
            "Epoch 35/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6536 - accuracy: 0.6204 - val_loss: 0.6127 - val_accuracy: 0.6786\n",
            "Epoch 36/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6463 - accuracy: 0.6307 - val_loss: 0.6124 - val_accuracy: 0.6751\n",
            "Epoch 37/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6413 - accuracy: 0.6287 - val_loss: 0.6102 - val_accuracy: 0.6812\n",
            "Epoch 38/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6455 - accuracy: 0.6331 - val_loss: 0.6104 - val_accuracy: 0.6829\n",
            "Epoch 39/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6443 - accuracy: 0.6331 - val_loss: 0.6082 - val_accuracy: 0.6847\n",
            "Epoch 40/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6373 - accuracy: 0.6479 - val_loss: 0.6072 - val_accuracy: 0.6838\n",
            "Epoch 41/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6338 - accuracy: 0.6442 - val_loss: 0.6035 - val_accuracy: 0.6916\n",
            "Epoch 42/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6319 - accuracy: 0.6609 - val_loss: 0.5970 - val_accuracy: 0.6943\n",
            "Epoch 43/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6255 - accuracy: 0.6577 - val_loss: 0.5891 - val_accuracy: 0.7152\n",
            "Epoch 44/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.6657 - val_loss: 0.5899 - val_accuracy: 0.7082\n",
            "Epoch 45/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6269 - accuracy: 0.6625 - val_loss: 0.5875 - val_accuracy: 0.7073\n",
            "Epoch 46/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6156 - accuracy: 0.6753 - val_loss: 0.5887 - val_accuracy: 0.7047\n",
            "Epoch 47/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6125 - accuracy: 0.6784 - val_loss: 0.5889 - val_accuracy: 0.7038\n",
            "Epoch 48/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6164 - accuracy: 0.6712 - val_loss: 0.5829 - val_accuracy: 0.7091\n",
            "Epoch 49/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6128 - accuracy: 0.6740 - val_loss: 0.5818 - val_accuracy: 0.7099\n",
            "Epoch 50/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6092 - accuracy: 0.6821 - val_loss: 0.5847 - val_accuracy: 0.7117\n",
            "Epoch 51/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6032 - accuracy: 0.6764 - val_loss: 0.5852 - val_accuracy: 0.7134\n",
            "Epoch 52/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.6001 - accuracy: 0.6890 - val_loss: 0.5832 - val_accuracy: 0.7160\n",
            "Epoch 53/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5939 - accuracy: 0.6971 - val_loss: 0.5830 - val_accuracy: 0.7134\n",
            "Epoch 54/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5950 - accuracy: 0.6966 - val_loss: 0.5844 - val_accuracy: 0.7117\n",
            "Epoch 55/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5920 - accuracy: 0.7014 - val_loss: 0.5828 - val_accuracy: 0.7117\n",
            "Epoch 56/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5828 - accuracy: 0.7093 - val_loss: 0.5855 - val_accuracy: 0.7030\n",
            "Epoch 57/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.6951 - val_loss: 0.5844 - val_accuracy: 0.7064\n",
            "Epoch 58/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5886 - accuracy: 0.6980 - val_loss: 0.5784 - val_accuracy: 0.7195\n",
            "Epoch 59/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5867 - accuracy: 0.7078 - val_loss: 0.5789 - val_accuracy: 0.7134\n",
            "Epoch 60/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5793 - accuracy: 0.7047 - val_loss: 0.5733 - val_accuracy: 0.7186\n",
            "Epoch 61/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5949 - accuracy: 0.6923 - val_loss: 0.5740 - val_accuracy: 0.7274\n",
            "Epoch 62/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5751 - accuracy: 0.7062 - val_loss: 0.5733 - val_accuracy: 0.7178\n",
            "Epoch 63/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5769 - accuracy: 0.7023 - val_loss: 0.5774 - val_accuracy: 0.7169\n",
            "Epoch 64/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5749 - accuracy: 0.7093 - val_loss: 0.5736 - val_accuracy: 0.7204\n",
            "Epoch 65/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5687 - accuracy: 0.7149 - val_loss: 0.5741 - val_accuracy: 0.7152\n",
            "Epoch 66/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5638 - accuracy: 0.7110 - val_loss: 0.5750 - val_accuracy: 0.7213\n",
            "Epoch 67/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5793 - accuracy: 0.7049 - val_loss: 0.5751 - val_accuracy: 0.7152\n",
            "Epoch 68/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5694 - accuracy: 0.7152 - val_loss: 0.5730 - val_accuracy: 0.7108\n",
            "Epoch 69/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5655 - accuracy: 0.7080 - val_loss: 0.5728 - val_accuracy: 0.7204\n",
            "Epoch 70/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.7230 - val_loss: 0.5725 - val_accuracy: 0.7160\n",
            "Epoch 71/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5594 - accuracy: 0.7173 - val_loss: 0.5714 - val_accuracy: 0.7125\n",
            "Epoch 72/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5558 - accuracy: 0.7112 - val_loss: 0.5734 - val_accuracy: 0.7152\n",
            "Epoch 73/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5595 - accuracy: 0.7195 - val_loss: 0.5758 - val_accuracy: 0.7169\n",
            "Epoch 74/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.7099 - val_loss: 0.5761 - val_accuracy: 0.7204\n",
            "Epoch 75/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7071 - val_loss: 0.5746 - val_accuracy: 0.7239\n",
            "Epoch 76/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7330 - val_loss: 0.5757 - val_accuracy: 0.7239\n",
            "Epoch 77/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5524 - accuracy: 0.7162 - val_loss: 0.5736 - val_accuracy: 0.7213\n",
            "Epoch 78/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5467 - accuracy: 0.7250 - val_loss: 0.5684 - val_accuracy: 0.7300\n",
            "Epoch 79/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5395 - accuracy: 0.7221 - val_loss: 0.5680 - val_accuracy: 0.7308\n",
            "Epoch 80/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7210 - val_loss: 0.5738 - val_accuracy: 0.7108\n",
            "Epoch 81/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7337 - val_loss: 0.5868 - val_accuracy: 0.6977\n",
            "Epoch 82/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7219 - val_loss: 0.5766 - val_accuracy: 0.7125\n",
            "Epoch 83/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5500 - accuracy: 0.7051 - val_loss: 0.5740 - val_accuracy: 0.7108\n",
            "Epoch 84/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5322 - accuracy: 0.7321 - val_loss: 0.5767 - val_accuracy: 0.7265\n",
            "Epoch 85/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5395 - accuracy: 0.7143 - val_loss: 0.5728 - val_accuracy: 0.7247\n",
            "Epoch 86/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7243 - val_loss: 0.5757 - val_accuracy: 0.7239\n",
            "Epoch 87/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.7263 - val_loss: 0.5755 - val_accuracy: 0.7256\n",
            "Epoch 88/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5230 - accuracy: 0.7267 - val_loss: 0.5772 - val_accuracy: 0.7152\n",
            "Epoch 89/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7167 - val_loss: 0.5793 - val_accuracy: 0.7099\n",
            "Epoch 90/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5184 - accuracy: 0.7300 - val_loss: 0.5858 - val_accuracy: 0.7143\n",
            "Epoch 91/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.7302 - val_loss: 0.5867 - val_accuracy: 0.7169\n",
            "Epoch 92/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5138 - accuracy: 0.7313 - val_loss: 0.5837 - val_accuracy: 0.7178\n",
            "Epoch 93/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.7432 - val_loss: 0.5832 - val_accuracy: 0.7221\n",
            "Epoch 94/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.5168 - accuracy: 0.7332 - val_loss: 0.5870 - val_accuracy: 0.7213\n",
            "Epoch 95/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5092 - accuracy: 0.7467 - val_loss: 0.5790 - val_accuracy: 0.7282\n",
            "Epoch 96/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7252 - val_loss: 0.5836 - val_accuracy: 0.7186\n",
            "Epoch 97/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7302 - val_loss: 0.5806 - val_accuracy: 0.7239\n",
            "Epoch 98/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7411 - val_loss: 0.5833 - val_accuracy: 0.7195\n",
            "Epoch 99/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.7369 - val_loss: 0.5767 - val_accuracy: 0.7230\n",
            "Epoch 100/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5137 - accuracy: 0.7319 - val_loss: 0.5777 - val_accuracy: 0.7239\n",
            "Epoch 101/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.7348 - val_loss: 0.5705 - val_accuracy: 0.7387\n",
            "Epoch 102/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7330 - val_loss: 0.5744 - val_accuracy: 0.7221\n",
            "Epoch 103/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7363 - val_loss: 0.5788 - val_accuracy: 0.7282\n",
            "Epoch 104/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7343 - val_loss: 0.5871 - val_accuracy: 0.7204\n",
            "Epoch 105/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7459 - val_loss: 0.5884 - val_accuracy: 0.7195\n",
            "Epoch 106/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.7343 - val_loss: 0.5845 - val_accuracy: 0.7195\n",
            "Epoch 107/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7459 - val_loss: 0.5826 - val_accuracy: 0.7317\n",
            "Epoch 108/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7378 - val_loss: 0.5863 - val_accuracy: 0.7334\n",
            "Epoch 109/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.7415 - val_loss: 0.5859 - val_accuracy: 0.7413\n",
            "Epoch 110/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4921 - accuracy: 0.7446 - val_loss: 0.5903 - val_accuracy: 0.7282\n",
            "Epoch 111/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7437 - val_loss: 0.5845 - val_accuracy: 0.7369\n",
            "Epoch 112/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7419 - val_loss: 0.5888 - val_accuracy: 0.7221\n",
            "Epoch 113/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.7337 - val_loss: 0.5795 - val_accuracy: 0.7282\n",
            "Epoch 114/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4891 - accuracy: 0.7411 - val_loss: 0.5825 - val_accuracy: 0.7282\n",
            "Epoch 115/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4818 - accuracy: 0.7426 - val_loss: 0.5887 - val_accuracy: 0.7230\n",
            "Epoch 116/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7443 - val_loss: 0.5925 - val_accuracy: 0.7204\n",
            "Epoch 117/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4851 - accuracy: 0.7496 - val_loss: 0.5982 - val_accuracy: 0.7239\n",
            "Epoch 118/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4900 - accuracy: 0.7426 - val_loss: 0.5967 - val_accuracy: 0.7282\n",
            "Epoch 119/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7511 - val_loss: 0.5904 - val_accuracy: 0.7308\n",
            "Epoch 120/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7413 - val_loss: 0.5960 - val_accuracy: 0.7334\n",
            "Epoch 121/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7348 - val_loss: 0.5918 - val_accuracy: 0.7282\n",
            "Epoch 122/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4837 - accuracy: 0.7452 - val_loss: 0.5948 - val_accuracy: 0.7282\n",
            "Epoch 123/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7517 - val_loss: 0.5987 - val_accuracy: 0.7343\n",
            "Epoch 124/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7522 - val_loss: 0.6050 - val_accuracy: 0.7326\n",
            "Epoch 125/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7511 - val_loss: 0.6071 - val_accuracy: 0.7308\n",
            "Epoch 126/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7611 - val_loss: 0.6022 - val_accuracy: 0.7282\n",
            "Epoch 127/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7578 - val_loss: 0.6087 - val_accuracy: 0.7256\n",
            "Epoch 128/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4794 - accuracy: 0.7491 - val_loss: 0.6064 - val_accuracy: 0.7291\n",
            "Epoch 129/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7591 - val_loss: 0.6061 - val_accuracy: 0.7274\n",
            "Epoch 130/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7596 - val_loss: 0.6090 - val_accuracy: 0.7204\n",
            "Epoch 131/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7624 - val_loss: 0.6146 - val_accuracy: 0.7186\n",
            "Epoch 132/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.7500 - val_loss: 0.6137 - val_accuracy: 0.7239\n",
            "Epoch 133/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7637 - val_loss: 0.6147 - val_accuracy: 0.7282\n",
            "Epoch 134/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7539 - val_loss: 0.6163 - val_accuracy: 0.7186\n",
            "Epoch 135/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7419 - val_loss: 0.6137 - val_accuracy: 0.7213\n",
            "Epoch 136/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7589 - val_loss: 0.6143 - val_accuracy: 0.7221\n",
            "Epoch 137/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7602 - val_loss: 0.6094 - val_accuracy: 0.7291\n",
            "Epoch 138/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7520 - val_loss: 0.6131 - val_accuracy: 0.7213\n",
            "Epoch 139/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7472 - val_loss: 0.6211 - val_accuracy: 0.7230\n",
            "Epoch 140/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7550 - val_loss: 0.6182 - val_accuracy: 0.7239\n",
            "Epoch 141/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.7591 - val_loss: 0.6213 - val_accuracy: 0.7221\n",
            "Epoch 142/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7554 - val_loss: 0.6204 - val_accuracy: 0.7300\n",
            "Epoch 143/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7504 - val_loss: 0.6186 - val_accuracy: 0.7300\n",
            "Epoch 144/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7535 - val_loss: 0.6207 - val_accuracy: 0.7282\n",
            "Epoch 145/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7456 - val_loss: 0.6117 - val_accuracy: 0.7378\n",
            "Epoch 146/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7596 - val_loss: 0.6163 - val_accuracy: 0.7291\n",
            "Epoch 147/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7554 - val_loss: 0.6155 - val_accuracy: 0.7291\n",
            "Epoch 148/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7541 - val_loss: 0.6151 - val_accuracy: 0.7256\n",
            "Epoch 149/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.7574 - val_loss: 0.6165 - val_accuracy: 0.7282\n",
            "Epoch 150/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7524 - val_loss: 0.6149 - val_accuracy: 0.7308\n",
            "Epoch 151/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7576 - val_loss: 0.6213 - val_accuracy: 0.7221\n",
            "Epoch 152/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7509 - val_loss: 0.6274 - val_accuracy: 0.7369\n",
            "Epoch 153/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7546 - val_loss: 0.6251 - val_accuracy: 0.7361\n",
            "Epoch 154/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.7731 - val_loss: 0.6232 - val_accuracy: 0.7274\n",
            "Epoch 155/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.7513 - val_loss: 0.6209 - val_accuracy: 0.7291\n",
            "Epoch 156/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7607 - val_loss: 0.6257 - val_accuracy: 0.7343\n",
            "Epoch 157/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7546 - val_loss: 0.6194 - val_accuracy: 0.7326\n",
            "Epoch 158/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7530 - val_loss: 0.6182 - val_accuracy: 0.7308\n",
            "Epoch 159/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7587 - val_loss: 0.6229 - val_accuracy: 0.7282\n",
            "Epoch 160/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7559 - val_loss: 0.6221 - val_accuracy: 0.7247\n",
            "Epoch 161/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7550 - val_loss: 0.6276 - val_accuracy: 0.7239\n",
            "Epoch 162/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7539 - val_loss: 0.6222 - val_accuracy: 0.7256\n",
            "Epoch 163/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7657 - val_loss: 0.6332 - val_accuracy: 0.7300\n",
            "Epoch 164/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7607 - val_loss: 0.6270 - val_accuracy: 0.7326\n",
            "Epoch 165/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7559 - val_loss: 0.6247 - val_accuracy: 0.7265\n",
            "Epoch 166/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7655 - val_loss: 0.6331 - val_accuracy: 0.7291\n",
            "Epoch 167/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7613 - val_loss: 0.6322 - val_accuracy: 0.7230\n",
            "Epoch 168/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7570 - val_loss: 0.6381 - val_accuracy: 0.7274\n",
            "Epoch 169/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7574 - val_loss: 0.6376 - val_accuracy: 0.7343\n",
            "Epoch 170/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.7596 - val_loss: 0.6410 - val_accuracy: 0.7317\n",
            "Epoch 171/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.7674 - val_loss: 0.6463 - val_accuracy: 0.7291\n",
            "Epoch 172/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7598 - val_loss: 0.6506 - val_accuracy: 0.7317\n",
            "Epoch 173/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.7644 - val_loss: 0.6577 - val_accuracy: 0.7265\n",
            "Epoch 174/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.7533 - val_loss: 0.6550 - val_accuracy: 0.7247\n",
            "Epoch 175/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7624 - val_loss: 0.6479 - val_accuracy: 0.7186\n",
            "Epoch 176/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7622 - val_loss: 0.6478 - val_accuracy: 0.7169\n",
            "Epoch 177/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7594 - val_loss: 0.6478 - val_accuracy: 0.7160\n",
            "Epoch 178/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7600 - val_loss: 0.6481 - val_accuracy: 0.7274\n",
            "Epoch 179/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7648 - val_loss: 0.6537 - val_accuracy: 0.7117\n",
            "Epoch 180/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7493 - val_loss: 0.6593 - val_accuracy: 0.7117\n",
            "Epoch 181/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.7698 - val_loss: 0.6560 - val_accuracy: 0.7247\n",
            "Epoch 182/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7609 - val_loss: 0.6631 - val_accuracy: 0.7204\n",
            "Epoch 183/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7605 - val_loss: 0.6722 - val_accuracy: 0.7134\n",
            "Epoch 184/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7639 - val_loss: 0.6666 - val_accuracy: 0.7195\n",
            "Epoch 185/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7622 - val_loss: 0.6666 - val_accuracy: 0.7178\n",
            "Epoch 186/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7657 - val_loss: 0.6625 - val_accuracy: 0.7247\n",
            "Epoch 187/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7631 - val_loss: 0.6645 - val_accuracy: 0.7239\n",
            "Epoch 188/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7657 - val_loss: 0.6652 - val_accuracy: 0.7239\n",
            "Epoch 189/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.7700 - val_loss: 0.6749 - val_accuracy: 0.7195\n",
            "Epoch 190/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.7570 - val_loss: 0.6801 - val_accuracy: 0.7230\n",
            "Epoch 191/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.7720 - val_loss: 0.6694 - val_accuracy: 0.7265\n",
            "Epoch 192/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7546 - val_loss: 0.6625 - val_accuracy: 0.7221\n",
            "Epoch 193/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7692 - val_loss: 0.6549 - val_accuracy: 0.7213\n",
            "Epoch 194/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7570 - val_loss: 0.6714 - val_accuracy: 0.7125\n",
            "Epoch 195/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.7666 - val_loss: 0.6664 - val_accuracy: 0.7152\n",
            "Epoch 196/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7642 - val_loss: 0.6739 - val_accuracy: 0.7117\n",
            "Epoch 197/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7648 - val_loss: 0.6773 - val_accuracy: 0.7134\n",
            "Epoch 198/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.7559 - val_loss: 0.6822 - val_accuracy: 0.7152\n",
            "Epoch 199/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.7591 - val_loss: 0.6829 - val_accuracy: 0.7274\n",
            "Epoch 200/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7642 - val_loss: 0.6846 - val_accuracy: 0.7178\n",
            "Epoch 201/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7602 - val_loss: 0.6796 - val_accuracy: 0.7213\n",
            "Epoch 202/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7520 - val_loss: 0.6688 - val_accuracy: 0.7282\n",
            "Epoch 203/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.7650 - val_loss: 0.6898 - val_accuracy: 0.7160\n",
            "Epoch 204/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7585 - val_loss: 0.6891 - val_accuracy: 0.7204\n",
            "Epoch 205/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7602 - val_loss: 0.6918 - val_accuracy: 0.7143\n",
            "Epoch 206/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7572 - val_loss: 0.6853 - val_accuracy: 0.7143\n",
            "Epoch 207/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.7696 - val_loss: 0.6969 - val_accuracy: 0.7256\n",
            "Epoch 208/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.7683 - val_loss: 0.6870 - val_accuracy: 0.7274\n",
            "Epoch 209/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7644 - val_loss: 0.6827 - val_accuracy: 0.7125\n",
            "Epoch 210/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7672 - val_loss: 0.6884 - val_accuracy: 0.7221\n",
            "Epoch 211/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7703 - val_loss: 0.6824 - val_accuracy: 0.7134\n",
            "Epoch 212/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7655 - val_loss: 0.6735 - val_accuracy: 0.7178\n",
            "Epoch 213/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.7546 - val_loss: 0.6811 - val_accuracy: 0.7152\n",
            "Epoch 214/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.7628 - val_loss: 0.6829 - val_accuracy: 0.7117\n",
            "Epoch 215/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.7646 - val_loss: 0.6870 - val_accuracy: 0.7091\n",
            "Epoch 216/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.7689 - val_loss: 0.6803 - val_accuracy: 0.7038\n",
            "Epoch 217/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.7735 - val_loss: 0.6865 - val_accuracy: 0.7091\n",
            "Epoch 218/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.7731 - val_loss: 0.6913 - val_accuracy: 0.7152\n",
            "Epoch 219/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.7683 - val_loss: 0.6991 - val_accuracy: 0.7186\n",
            "Epoch 220/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.7696 - val_loss: 0.6917 - val_accuracy: 0.7143\n",
            "Epoch 221/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.7574 - val_loss: 0.7004 - val_accuracy: 0.7160\n",
            "Epoch 222/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.7624 - val_loss: 0.6998 - val_accuracy: 0.7117\n",
            "Epoch 223/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.7646 - val_loss: 0.7030 - val_accuracy: 0.7160\n",
            "Epoch 224/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.7561 - val_loss: 0.6953 - val_accuracy: 0.7117\n",
            "Epoch 225/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7646 - val_loss: 0.7050 - val_accuracy: 0.7073\n",
            "Epoch 226/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.7707 - val_loss: 0.6976 - val_accuracy: 0.7099\n",
            "Epoch 227/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7598 - val_loss: 0.6880 - val_accuracy: 0.7117\n",
            "Epoch 228/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7594 - val_loss: 0.6848 - val_accuracy: 0.7143\n",
            "Epoch 229/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7689 - val_loss: 0.6941 - val_accuracy: 0.7134\n",
            "Epoch 230/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7559 - val_loss: 0.7006 - val_accuracy: 0.7099\n",
            "Epoch 231/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.7581 - val_loss: 0.6917 - val_accuracy: 0.7108\n",
            "Epoch 232/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.7631 - val_loss: 0.6904 - val_accuracy: 0.7134\n",
            "Epoch 233/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7696 - val_loss: 0.6941 - val_accuracy: 0.7099\n",
            "Epoch 234/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.7679 - val_loss: 0.7005 - val_accuracy: 0.7056\n",
            "Epoch 235/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7587 - val_loss: 0.6946 - val_accuracy: 0.7082\n",
            "Epoch 236/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.7605 - val_loss: 0.6876 - val_accuracy: 0.7047\n",
            "Epoch 237/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.7713 - val_loss: 0.7018 - val_accuracy: 0.7108\n",
            "Epoch 238/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.7635 - val_loss: 0.7046 - val_accuracy: 0.7108\n",
            "Epoch 239/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7639 - val_loss: 0.7064 - val_accuracy: 0.6986\n",
            "Epoch 240/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.7639 - val_loss: 0.7077 - val_accuracy: 0.7047\n",
            "Epoch 241/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7635 - val_loss: 0.7012 - val_accuracy: 0.7125\n",
            "Epoch 242/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7615 - val_loss: 0.7105 - val_accuracy: 0.7091\n",
            "Epoch 243/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7687 - val_loss: 0.7213 - val_accuracy: 0.7134\n",
            "Epoch 244/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7533 - val_loss: 0.7050 - val_accuracy: 0.7038\n",
            "Epoch 245/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.7596 - val_loss: 0.7099 - val_accuracy: 0.7047\n",
            "Epoch 246/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.7700 - val_loss: 0.7137 - val_accuracy: 0.7091\n",
            "Epoch 247/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7742 - val_loss: 0.7264 - val_accuracy: 0.7117\n",
            "Epoch 248/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.7694 - val_loss: 0.7151 - val_accuracy: 0.7143\n",
            "Epoch 249/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.7676 - val_loss: 0.7151 - val_accuracy: 0.7047\n",
            "Epoch 250/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.7674 - val_loss: 0.7206 - val_accuracy: 0.7134\n",
            "Epoch 251/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.7676 - val_loss: 0.7229 - val_accuracy: 0.7213\n",
            "Epoch 252/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.7707 - val_loss: 0.7117 - val_accuracy: 0.7169\n",
            "Epoch 253/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.7655 - val_loss: 0.7147 - val_accuracy: 0.7143\n",
            "Epoch 254/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.7750 - val_loss: 0.7226 - val_accuracy: 0.7134\n",
            "Epoch 255/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.7672 - val_loss: 0.7248 - val_accuracy: 0.7012\n",
            "Epoch 256/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.7659 - val_loss: 0.7313 - val_accuracy: 0.7160\n",
            "Epoch 257/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7541 - val_loss: 0.7210 - val_accuracy: 0.7082\n",
            "Epoch 258/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.7602 - val_loss: 0.7276 - val_accuracy: 0.7012\n",
            "Epoch 259/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.7707 - val_loss: 0.7240 - val_accuracy: 0.7021\n",
            "Epoch 260/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.7639 - val_loss: 0.7400 - val_accuracy: 0.7021\n",
            "Epoch 261/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.7700 - val_loss: 0.7451 - val_accuracy: 0.7056\n",
            "Epoch 262/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7613 - val_loss: 0.7336 - val_accuracy: 0.7082\n",
            "Epoch 263/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.7485 - val_loss: 0.7158 - val_accuracy: 0.7108\n",
            "Epoch 264/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.7731 - val_loss: 0.7187 - val_accuracy: 0.7099\n",
            "Epoch 265/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7692 - val_loss: 0.7208 - val_accuracy: 0.7117\n",
            "Epoch 266/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.7672 - val_loss: 0.7222 - val_accuracy: 0.7169\n",
            "Epoch 267/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.7722 - val_loss: 0.7231 - val_accuracy: 0.7143\n",
            "Epoch 268/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.7718 - val_loss: 0.7185 - val_accuracy: 0.7108\n",
            "Epoch 269/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.7753 - val_loss: 0.7227 - val_accuracy: 0.7108\n",
            "Epoch 270/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.7737 - val_loss: 0.7171 - val_accuracy: 0.7108\n",
            "Epoch 271/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.7620 - val_loss: 0.7149 - val_accuracy: 0.7064\n",
            "Epoch 272/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.7668 - val_loss: 0.7337 - val_accuracy: 0.7091\n",
            "Epoch 273/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.7661 - val_loss: 0.7360 - val_accuracy: 0.7108\n",
            "Epoch 274/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.7759 - val_loss: 0.7367 - val_accuracy: 0.7117\n",
            "Epoch 275/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.7748 - val_loss: 0.7375 - val_accuracy: 0.7099\n",
            "Epoch 276/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4097 - accuracy: 0.7703 - val_loss: 0.7391 - val_accuracy: 0.7099\n",
            "Epoch 277/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.7596 - val_loss: 0.7356 - val_accuracy: 0.7125\n",
            "Epoch 278/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.7692 - val_loss: 0.7291 - val_accuracy: 0.7108\n",
            "Epoch 279/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.7753 - val_loss: 0.7415 - val_accuracy: 0.7021\n",
            "Epoch 280/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.7759 - val_loss: 0.7347 - val_accuracy: 0.7064\n",
            "Epoch 281/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.7655 - val_loss: 0.7462 - val_accuracy: 0.7012\n",
            "Epoch 282/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.7726 - val_loss: 0.7470 - val_accuracy: 0.7073\n",
            "Epoch 283/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.7694 - val_loss: 0.7386 - val_accuracy: 0.6995\n",
            "Epoch 284/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.7711 - val_loss: 0.7419 - val_accuracy: 0.7108\n",
            "Epoch 285/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.7679 - val_loss: 0.7293 - val_accuracy: 0.7125\n",
            "Epoch 286/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.7672 - val_loss: 0.7268 - val_accuracy: 0.7099\n",
            "Epoch 287/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.7635 - val_loss: 0.7276 - val_accuracy: 0.7064\n",
            "Epoch 288/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.7646 - val_loss: 0.7372 - val_accuracy: 0.7064\n",
            "Epoch 289/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.7591 - val_loss: 0.7338 - val_accuracy: 0.7064\n",
            "Epoch 290/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.7594 - val_loss: 0.7391 - val_accuracy: 0.7082\n",
            "Epoch 291/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.7676 - val_loss: 0.7374 - val_accuracy: 0.7038\n",
            "Epoch 292/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.7676 - val_loss: 0.7234 - val_accuracy: 0.6951\n",
            "Epoch 293/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7624 - val_loss: 0.7337 - val_accuracy: 0.6969\n",
            "Epoch 294/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.7589 - val_loss: 0.7433 - val_accuracy: 0.7038\n",
            "Epoch 295/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.7605 - val_loss: 0.7459 - val_accuracy: 0.6995\n",
            "Epoch 296/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.7674 - val_loss: 0.7486 - val_accuracy: 0.7056\n",
            "Epoch 297/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.7676 - val_loss: 0.7495 - val_accuracy: 0.7021\n",
            "Epoch 298/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.7576 - val_loss: 0.7611 - val_accuracy: 0.6986\n",
            "Epoch 299/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.7624 - val_loss: 0.7583 - val_accuracy: 0.7082\n",
            "Epoch 300/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7583 - val_loss: 0.7504 - val_accuracy: 0.6847\n",
            "Epoch 301/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.7605 - val_loss: 0.7570 - val_accuracy: 0.6951\n",
            "Epoch 302/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.7770 - val_loss: 0.7616 - val_accuracy: 0.7134\n",
            "Epoch 303/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.7659 - val_loss: 0.7574 - val_accuracy: 0.7091\n",
            "Epoch 304/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.7631 - val_loss: 0.7624 - val_accuracy: 0.7082\n",
            "Epoch 305/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7480 - val_loss: 0.7612 - val_accuracy: 0.7056\n",
            "Epoch 306/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.7628 - val_loss: 0.7693 - val_accuracy: 0.7038\n",
            "Epoch 307/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.7565 - val_loss: 0.7585 - val_accuracy: 0.6986\n",
            "Epoch 308/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.7681 - val_loss: 0.7753 - val_accuracy: 0.7108\n",
            "Epoch 309/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.7705 - val_loss: 0.7680 - val_accuracy: 0.7073\n",
            "Epoch 310/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.7676 - val_loss: 0.7692 - val_accuracy: 0.7047\n",
            "Epoch 311/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.7670 - val_loss: 0.7609 - val_accuracy: 0.7056\n",
            "Epoch 312/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.7683 - val_loss: 0.7665 - val_accuracy: 0.7064\n",
            "Epoch 313/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.7646 - val_loss: 0.7794 - val_accuracy: 0.7108\n",
            "Epoch 314/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7709 - val_loss: 0.7683 - val_accuracy: 0.7030\n",
            "Epoch 315/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.7755 - val_loss: 0.7701 - val_accuracy: 0.7073\n",
            "Epoch 316/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.7722 - val_loss: 0.7647 - val_accuracy: 0.7047\n",
            "Epoch 317/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.7700 - val_loss: 0.7731 - val_accuracy: 0.7073\n",
            "Epoch 318/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.7720 - val_loss: 0.7655 - val_accuracy: 0.7021\n",
            "Epoch 319/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.7711 - val_loss: 0.7703 - val_accuracy: 0.7099\n",
            "Epoch 320/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.7624 - val_loss: 0.7592 - val_accuracy: 0.6969\n",
            "Epoch 321/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.7620 - val_loss: 0.7506 - val_accuracy: 0.7012\n",
            "Epoch 322/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.7720 - val_loss: 0.7433 - val_accuracy: 0.6925\n",
            "Epoch 323/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.7761 - val_loss: 0.7524 - val_accuracy: 0.6925\n",
            "Epoch 324/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4083 - accuracy: 0.7628 - val_loss: 0.7598 - val_accuracy: 0.6925\n",
            "Epoch 325/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.7661 - val_loss: 0.7730 - val_accuracy: 0.6995\n",
            "Epoch 326/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.7670 - val_loss: 0.7846 - val_accuracy: 0.6986\n",
            "Epoch 327/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.7744 - val_loss: 0.7856 - val_accuracy: 0.7003\n",
            "Epoch 328/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.7746 - val_loss: 0.7860 - val_accuracy: 0.7038\n",
            "Epoch 329/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.7811 - val_loss: 0.8046 - val_accuracy: 0.6977\n",
            "Epoch 330/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.7748 - val_loss: 0.8006 - val_accuracy: 0.7021\n",
            "Epoch 331/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.7733 - val_loss: 0.8018 - val_accuracy: 0.7012\n",
            "Epoch 332/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.7716 - val_loss: 0.7975 - val_accuracy: 0.6943\n",
            "Epoch 333/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.7705 - val_loss: 0.7959 - val_accuracy: 0.6925\n",
            "Epoch 334/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.7716 - val_loss: 0.7986 - val_accuracy: 0.6916\n",
            "Epoch 335/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.7724 - val_loss: 0.8042 - val_accuracy: 0.6977\n",
            "Epoch 336/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.7663 - val_loss: 0.7859 - val_accuracy: 0.6899\n",
            "Epoch 337/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.7718 - val_loss: 0.7748 - val_accuracy: 0.7021\n",
            "Epoch 338/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.7679 - val_loss: 0.7760 - val_accuracy: 0.6951\n",
            "Epoch 339/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.7703 - val_loss: 0.7926 - val_accuracy: 0.7021\n",
            "Epoch 340/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7676 - val_loss: 0.8040 - val_accuracy: 0.7038\n",
            "Epoch 341/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.7628 - val_loss: 0.8021 - val_accuracy: 0.6986\n",
            "Epoch 342/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.7683 - val_loss: 0.8049 - val_accuracy: 0.6925\n",
            "Epoch 343/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.7718 - val_loss: 0.7912 - val_accuracy: 0.6873\n",
            "Epoch 344/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.7742 - val_loss: 0.7874 - val_accuracy: 0.6986\n",
            "Epoch 345/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.7681 - val_loss: 0.7654 - val_accuracy: 0.6847\n",
            "Epoch 346/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.7698 - val_loss: 0.7657 - val_accuracy: 0.6951\n",
            "Epoch 347/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.7698 - val_loss: 0.7679 - val_accuracy: 0.7073\n",
            "Epoch 348/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.7696 - val_loss: 0.7624 - val_accuracy: 0.7030\n",
            "Epoch 349/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.7663 - val_loss: 0.7585 - val_accuracy: 0.7021\n",
            "Epoch 350/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.7679 - val_loss: 0.7695 - val_accuracy: 0.7064\n",
            "Epoch 351/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.7683 - val_loss: 0.7693 - val_accuracy: 0.6925\n",
            "Epoch 352/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.7613 - val_loss: 0.7699 - val_accuracy: 0.6916\n",
            "Epoch 353/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.7740 - val_loss: 0.7872 - val_accuracy: 0.7003\n",
            "Epoch 354/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.7737 - val_loss: 0.7991 - val_accuracy: 0.7073\n",
            "Epoch 355/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.7761 - val_loss: 0.7797 - val_accuracy: 0.7082\n",
            "Epoch 356/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.7687 - val_loss: 0.7707 - val_accuracy: 0.7038\n",
            "Epoch 357/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.7733 - val_loss: 0.7724 - val_accuracy: 0.6995\n",
            "Epoch 358/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4186 - accuracy: 0.7807 - val_loss: 0.7570 - val_accuracy: 0.6986\n",
            "Epoch 359/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.7729 - val_loss: 0.7533 - val_accuracy: 0.7021\n",
            "Epoch 360/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.7713 - val_loss: 0.7643 - val_accuracy: 0.6995\n",
            "Epoch 361/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.7803 - val_loss: 0.7745 - val_accuracy: 0.6986\n",
            "Epoch 362/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.7831 - val_loss: 0.7849 - val_accuracy: 0.7064\n",
            "Epoch 363/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.7713 - val_loss: 0.7751 - val_accuracy: 0.7108\n",
            "Epoch 364/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.7615 - val_loss: 0.7837 - val_accuracy: 0.7082\n",
            "Epoch 365/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.7689 - val_loss: 0.7821 - val_accuracy: 0.7143\n",
            "Epoch 366/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.7840 - val_loss: 0.7849 - val_accuracy: 0.7003\n",
            "Epoch 367/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.7772 - val_loss: 0.7957 - val_accuracy: 0.7091\n",
            "Epoch 368/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.7700 - val_loss: 0.7895 - val_accuracy: 0.7108\n",
            "Epoch 369/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.7774 - val_loss: 0.7798 - val_accuracy: 0.7012\n",
            "Epoch 370/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.7650 - val_loss: 0.7805 - val_accuracy: 0.7047\n",
            "Epoch 371/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.7661 - val_loss: 0.7878 - val_accuracy: 0.7099\n",
            "Epoch 372/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.7644 - val_loss: 0.7797 - val_accuracy: 0.7021\n",
            "Epoch 373/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.7602 - val_loss: 0.7937 - val_accuracy: 0.7134\n",
            "Epoch 374/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.7726 - val_loss: 0.7883 - val_accuracy: 0.6943\n",
            "Epoch 375/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.7707 - val_loss: 0.8025 - val_accuracy: 0.7003\n",
            "Epoch 376/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.7722 - val_loss: 0.8140 - val_accuracy: 0.7047\n",
            "Epoch 377/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.7578 - val_loss: 0.7889 - val_accuracy: 0.7038\n",
            "Epoch 378/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.7709 - val_loss: 0.7867 - val_accuracy: 0.6995\n",
            "Epoch 379/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.7844 - val_loss: 0.8049 - val_accuracy: 0.6995\n",
            "Epoch 380/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.7809 - val_loss: 0.8103 - val_accuracy: 0.6995\n",
            "Epoch 381/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.7746 - val_loss: 0.8159 - val_accuracy: 0.7038\n",
            "Epoch 382/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.7687 - val_loss: 0.8066 - val_accuracy: 0.6986\n",
            "Epoch 383/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.7759 - val_loss: 0.7997 - val_accuracy: 0.7012\n",
            "Epoch 384/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.7716 - val_loss: 0.7992 - val_accuracy: 0.6934\n",
            "Epoch 385/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.7820 - val_loss: 0.8167 - val_accuracy: 0.7099\n",
            "Epoch 386/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.7733 - val_loss: 0.8126 - val_accuracy: 0.7047\n",
            "Epoch 387/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.7711 - val_loss: 0.7990 - val_accuracy: 0.7056\n",
            "Epoch 388/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.7761 - val_loss: 0.8008 - val_accuracy: 0.6986\n",
            "Epoch 389/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.7787 - val_loss: 0.8000 - val_accuracy: 0.6977\n",
            "Epoch 390/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.7820 - val_loss: 0.7913 - val_accuracy: 0.7012\n",
            "Epoch 391/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.7777 - val_loss: 0.7996 - val_accuracy: 0.7012\n",
            "Epoch 392/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.7790 - val_loss: 0.7939 - val_accuracy: 0.6916\n",
            "Epoch 393/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.7779 - val_loss: 0.7906 - val_accuracy: 0.6899\n",
            "Epoch 394/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.7737 - val_loss: 0.8068 - val_accuracy: 0.6934\n",
            "Epoch 395/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.7759 - val_loss: 0.8151 - val_accuracy: 0.7012\n",
            "Epoch 396/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4055 - accuracy: 0.7696 - val_loss: 0.8178 - val_accuracy: 0.7038\n",
            "Epoch 397/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.7785 - val_loss: 0.8121 - val_accuracy: 0.7056\n",
            "Epoch 398/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.7774 - val_loss: 0.7996 - val_accuracy: 0.6986\n",
            "Epoch 399/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.7764 - val_loss: 0.7961 - val_accuracy: 0.7064\n",
            "Epoch 400/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.7816 - val_loss: 0.8004 - val_accuracy: 0.7108\n",
            "Epoch 401/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.7698 - val_loss: 0.7803 - val_accuracy: 0.7160\n",
            "Epoch 402/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.7726 - val_loss: 0.7752 - val_accuracy: 0.7099\n",
            "Epoch 403/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.7831 - val_loss: 0.7940 - val_accuracy: 0.7030\n",
            "Epoch 404/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.7798 - val_loss: 0.8012 - val_accuracy: 0.7134\n",
            "Epoch 405/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.7666 - val_loss: 0.7996 - val_accuracy: 0.7073\n",
            "Epoch 406/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.7766 - val_loss: 0.7902 - val_accuracy: 0.7108\n",
            "Epoch 407/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.7740 - val_loss: 0.7671 - val_accuracy: 0.7082\n",
            "Epoch 408/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.7805 - val_loss: 0.7799 - val_accuracy: 0.7064\n",
            "Epoch 409/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.7757 - val_loss: 0.7804 - val_accuracy: 0.7073\n",
            "Epoch 410/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.7711 - val_loss: 0.7928 - val_accuracy: 0.7091\n",
            "Epoch 411/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.7711 - val_loss: 0.7804 - val_accuracy: 0.7047\n",
            "Epoch 412/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.7713 - val_loss: 0.7961 - val_accuracy: 0.7064\n",
            "Epoch 413/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.7783 - val_loss: 0.7973 - val_accuracy: 0.7021\n",
            "Epoch 414/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.7766 - val_loss: 0.7997 - val_accuracy: 0.6977\n",
            "Epoch 415/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.7807 - val_loss: 0.8047 - val_accuracy: 0.6986\n",
            "Epoch 416/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.7716 - val_loss: 0.8230 - val_accuracy: 0.6986\n",
            "Epoch 417/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.7801 - val_loss: 0.8257 - val_accuracy: 0.6934\n",
            "Epoch 418/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.7750 - val_loss: 0.8210 - val_accuracy: 0.6873\n",
            "Epoch 419/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.7787 - val_loss: 0.8160 - val_accuracy: 0.6943\n",
            "Epoch 420/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.7798 - val_loss: 0.8292 - val_accuracy: 0.6951\n",
            "Epoch 421/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.7755 - val_loss: 0.8255 - val_accuracy: 0.7047\n",
            "Epoch 422/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.7748 - val_loss: 0.8293 - val_accuracy: 0.7003\n",
            "Epoch 423/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.7676 - val_loss: 0.8177 - val_accuracy: 0.6986\n",
            "Epoch 424/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.7764 - val_loss: 0.8049 - val_accuracy: 0.7003\n",
            "Epoch 425/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.7720 - val_loss: 0.8021 - val_accuracy: 0.7047\n",
            "Epoch 426/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.7768 - val_loss: 0.7878 - val_accuracy: 0.7038\n",
            "Epoch 427/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.7770 - val_loss: 0.7880 - val_accuracy: 0.7073\n",
            "Epoch 428/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.7707 - val_loss: 0.7904 - val_accuracy: 0.7003\n",
            "Epoch 429/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3985 - accuracy: 0.7700 - val_loss: 0.7926 - val_accuracy: 0.7038\n",
            "Epoch 430/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.7700 - val_loss: 0.7912 - val_accuracy: 0.7021\n",
            "Epoch 431/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.7829 - val_loss: 0.8239 - val_accuracy: 0.7030\n",
            "Epoch 432/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.7785 - val_loss: 0.8242 - val_accuracy: 0.6969\n",
            "Epoch 433/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.7711 - val_loss: 0.8022 - val_accuracy: 0.6890\n",
            "Epoch 434/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.7785 - val_loss: 0.7946 - val_accuracy: 0.7056\n",
            "Epoch 435/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.7816 - val_loss: 0.7999 - val_accuracy: 0.7056\n",
            "Epoch 436/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.7772 - val_loss: 0.7921 - val_accuracy: 0.7038\n",
            "Epoch 437/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.7814 - val_loss: 0.8093 - val_accuracy: 0.7012\n",
            "Epoch 438/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.7833 - val_loss: 0.8065 - val_accuracy: 0.7047\n",
            "Epoch 439/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.7794 - val_loss: 0.7995 - val_accuracy: 0.7082\n",
            "Epoch 440/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.7761 - val_loss: 0.8050 - val_accuracy: 0.7064\n",
            "Epoch 441/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.7718 - val_loss: 0.7852 - val_accuracy: 0.7125\n",
            "Epoch 442/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.7766 - val_loss: 0.7869 - val_accuracy: 0.6960\n",
            "Epoch 443/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.7703 - val_loss: 0.7886 - val_accuracy: 0.6882\n",
            "Epoch 444/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.7720 - val_loss: 0.7900 - val_accuracy: 0.6908\n",
            "Epoch 445/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.7755 - val_loss: 0.7967 - val_accuracy: 0.6890\n",
            "Epoch 446/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.7711 - val_loss: 0.8055 - val_accuracy: 0.7003\n",
            "Epoch 447/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.7785 - val_loss: 0.7986 - val_accuracy: 0.6995\n",
            "Epoch 448/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.7761 - val_loss: 0.8039 - val_accuracy: 0.6960\n",
            "Epoch 449/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.7848 - val_loss: 0.8010 - val_accuracy: 0.7047\n",
            "Epoch 450/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.7700 - val_loss: 0.8037 - val_accuracy: 0.7056\n",
            "Epoch 451/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.7718 - val_loss: 0.7883 - val_accuracy: 0.7056\n",
            "Epoch 452/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.7790 - val_loss: 0.7828 - val_accuracy: 0.7073\n",
            "Epoch 453/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.7650 - val_loss: 0.7820 - val_accuracy: 0.7003\n",
            "Epoch 454/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.7731 - val_loss: 0.7908 - val_accuracy: 0.7047\n",
            "Epoch 455/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.7724 - val_loss: 0.7905 - val_accuracy: 0.7082\n",
            "Epoch 456/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.7790 - val_loss: 0.8068 - val_accuracy: 0.7030\n",
            "Epoch 457/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.7764 - val_loss: 0.8011 - val_accuracy: 0.7047\n",
            "Epoch 458/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.7724 - val_loss: 0.8074 - val_accuracy: 0.7099\n",
            "Epoch 459/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.7746 - val_loss: 0.8035 - val_accuracy: 0.7047\n",
            "Epoch 460/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.7748 - val_loss: 0.8062 - val_accuracy: 0.7003\n",
            "Epoch 461/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3904 - accuracy: 0.7759 - val_loss: 0.8236 - val_accuracy: 0.7091\n",
            "Epoch 462/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.7814 - val_loss: 0.8148 - val_accuracy: 0.7012\n",
            "Epoch 463/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.7635 - val_loss: 0.8204 - val_accuracy: 0.7056\n",
            "Epoch 464/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.7672 - val_loss: 0.8076 - val_accuracy: 0.7108\n",
            "Epoch 465/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.7803 - val_loss: 0.8143 - val_accuracy: 0.7073\n",
            "Epoch 466/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.7818 - val_loss: 0.8142 - val_accuracy: 0.7056\n",
            "Epoch 467/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.7718 - val_loss: 0.8094 - val_accuracy: 0.7091\n",
            "Epoch 468/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.7764 - val_loss: 0.8140 - val_accuracy: 0.7091\n",
            "Epoch 469/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.7687 - val_loss: 0.8057 - val_accuracy: 0.7064\n",
            "Epoch 470/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.7713 - val_loss: 0.8079 - val_accuracy: 0.6977\n",
            "Epoch 471/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.7696 - val_loss: 0.8025 - val_accuracy: 0.7012\n",
            "Epoch 472/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3942 - accuracy: 0.7737 - val_loss: 0.8142 - val_accuracy: 0.7125\n",
            "Epoch 473/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3934 - accuracy: 0.7718 - val_loss: 0.8114 - val_accuracy: 0.7160\n",
            "Epoch 474/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3865 - accuracy: 0.7705 - val_loss: 0.8065 - val_accuracy: 0.7099\n",
            "Epoch 475/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3745 - accuracy: 0.7840 - val_loss: 0.8151 - val_accuracy: 0.7099\n",
            "Epoch 476/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.7798 - val_loss: 0.8203 - val_accuracy: 0.7082\n",
            "Epoch 477/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.7785 - val_loss: 0.8069 - val_accuracy: 0.7047\n",
            "Epoch 478/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3864 - accuracy: 0.7816 - val_loss: 0.8128 - val_accuracy: 0.7047\n",
            "Epoch 479/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.7670 - val_loss: 0.8186 - val_accuracy: 0.7021\n",
            "Epoch 480/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.7694 - val_loss: 0.8222 - val_accuracy: 0.7056\n",
            "Epoch 481/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3843 - accuracy: 0.7811 - val_loss: 0.8210 - val_accuracy: 0.7082\n",
            "Epoch 482/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.7814 - val_loss: 0.8136 - val_accuracy: 0.7073\n",
            "Epoch 483/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.7820 - val_loss: 0.8229 - val_accuracy: 0.7030\n",
            "Epoch 484/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.7720 - val_loss: 0.8227 - val_accuracy: 0.7021\n",
            "Epoch 485/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.7744 - val_loss: 0.8402 - val_accuracy: 0.6977\n",
            "Epoch 486/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.7737 - val_loss: 0.8257 - val_accuracy: 0.7003\n",
            "Epoch 487/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.7676 - val_loss: 0.8151 - val_accuracy: 0.6969\n",
            "Epoch 488/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3862 - accuracy: 0.7620 - val_loss: 0.8262 - val_accuracy: 0.6925\n",
            "Epoch 489/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4065 - accuracy: 0.7661 - val_loss: 0.8250 - val_accuracy: 0.7030\n",
            "Epoch 490/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.7779 - val_loss: 0.8311 - val_accuracy: 0.7099\n",
            "Epoch 491/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.7779 - val_loss: 0.8236 - val_accuracy: 0.7143\n",
            "Epoch 492/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.7611 - val_loss: 0.8203 - val_accuracy: 0.6934\n",
            "Epoch 493/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.7655 - val_loss: 0.8077 - val_accuracy: 0.6916\n",
            "Epoch 494/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.7716 - val_loss: 0.8117 - val_accuracy: 0.6977\n",
            "Epoch 495/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.7698 - val_loss: 0.8147 - val_accuracy: 0.6969\n",
            "Epoch 496/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.7631 - val_loss: 0.8148 - val_accuracy: 0.6995\n",
            "Epoch 497/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.7659 - val_loss: 0.8176 - val_accuracy: 0.7021\n",
            "Epoch 498/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.7642 - val_loss: 0.8233 - val_accuracy: 0.7091\n",
            "Epoch 499/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.7748 - val_loss: 0.8161 - val_accuracy: 0.7047\n",
            "Epoch 500/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.7731 - val_loss: 0.8242 - val_accuracy: 0.7108\n",
            "Epoch 501/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.7703 - val_loss: 0.8186 - val_accuracy: 0.7117\n",
            "Epoch 502/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.7709 - val_loss: 0.8076 - val_accuracy: 0.7038\n",
            "Epoch 503/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.7713 - val_loss: 0.8107 - val_accuracy: 0.6995\n",
            "Epoch 504/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.7628 - val_loss: 0.8209 - val_accuracy: 0.7012\n",
            "Epoch 505/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.7750 - val_loss: 0.8269 - val_accuracy: 0.6977\n",
            "Epoch 506/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.7746 - val_loss: 0.8262 - val_accuracy: 0.7030\n",
            "Epoch 507/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.7618 - val_loss: 0.8060 - val_accuracy: 0.6899\n",
            "Epoch 508/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.7692 - val_loss: 0.8193 - val_accuracy: 0.6916\n",
            "Epoch 509/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.7698 - val_loss: 0.8344 - val_accuracy: 0.6986\n",
            "Epoch 510/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.7685 - val_loss: 0.8335 - val_accuracy: 0.7038\n",
            "Epoch 511/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4166 - accuracy: 0.7631 - val_loss: 0.8046 - val_accuracy: 0.7030\n",
            "Epoch 512/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.7787 - val_loss: 0.8046 - val_accuracy: 0.7030\n",
            "Epoch 513/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.7668 - val_loss: 0.8100 - val_accuracy: 0.7003\n",
            "Epoch 514/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.7737 - val_loss: 0.8291 - val_accuracy: 0.7082\n",
            "Epoch 515/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.7631 - val_loss: 0.8257 - val_accuracy: 0.7012\n",
            "Epoch 516/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.7761 - val_loss: 0.8240 - val_accuracy: 0.7056\n",
            "Epoch 517/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.7744 - val_loss: 0.8241 - val_accuracy: 0.6951\n",
            "Epoch 518/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.7744 - val_loss: 0.8230 - val_accuracy: 0.7030\n",
            "Epoch 519/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.7713 - val_loss: 0.8182 - val_accuracy: 0.7108\n",
            "Epoch 520/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4011 - accuracy: 0.7652 - val_loss: 0.8143 - val_accuracy: 0.7038\n",
            "Epoch 521/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3795 - accuracy: 0.7814 - val_loss: 0.8280 - val_accuracy: 0.7064\n",
            "Epoch 522/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3725 - accuracy: 0.7809 - val_loss: 0.8312 - val_accuracy: 0.7056\n",
            "Epoch 523/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.7746 - val_loss: 0.8169 - val_accuracy: 0.6995\n",
            "Epoch 524/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.7827 - val_loss: 0.8275 - val_accuracy: 0.7038\n",
            "Epoch 525/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.7761 - val_loss: 0.8345 - val_accuracy: 0.7073\n",
            "Epoch 526/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.7785 - val_loss: 0.8413 - val_accuracy: 0.6969\n",
            "Epoch 527/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.7661 - val_loss: 0.8326 - val_accuracy: 0.6916\n",
            "Epoch 528/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3908 - accuracy: 0.7700 - val_loss: 0.8299 - val_accuracy: 0.7108\n",
            "Epoch 529/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.7731 - val_loss: 0.8109 - val_accuracy: 0.7012\n",
            "Epoch 530/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.7766 - val_loss: 0.8205 - val_accuracy: 0.6969\n",
            "Epoch 531/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.7659 - val_loss: 0.8235 - val_accuracy: 0.6986\n",
            "Epoch 532/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.7735 - val_loss: 0.8380 - val_accuracy: 0.6960\n",
            "Epoch 533/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3884 - accuracy: 0.7724 - val_loss: 0.8382 - val_accuracy: 0.6986\n",
            "Epoch 534/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3926 - accuracy: 0.7777 - val_loss: 0.8376 - val_accuracy: 0.7021\n",
            "Epoch 535/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.7707 - val_loss: 0.8392 - val_accuracy: 0.7073\n",
            "Epoch 536/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.7783 - val_loss: 0.8434 - val_accuracy: 0.7073\n",
            "Epoch 537/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.7809 - val_loss: 0.8285 - val_accuracy: 0.7003\n",
            "Epoch 538/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.7779 - val_loss: 0.8081 - val_accuracy: 0.6977\n",
            "Epoch 539/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.7707 - val_loss: 0.8331 - val_accuracy: 0.7038\n",
            "Epoch 540/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.7559 - val_loss: 0.8236 - val_accuracy: 0.6934\n",
            "Epoch 541/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.7687 - val_loss: 0.8296 - val_accuracy: 0.6960\n",
            "Epoch 542/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3785 - accuracy: 0.7742 - val_loss: 0.8472 - val_accuracy: 0.6969\n",
            "Epoch 543/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.7805 - val_loss: 0.8443 - val_accuracy: 0.7030\n",
            "Epoch 544/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.7737 - val_loss: 0.8457 - val_accuracy: 0.7030\n",
            "Epoch 545/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.7755 - val_loss: 0.8473 - val_accuracy: 0.7073\n",
            "Epoch 546/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.7792 - val_loss: 0.8480 - val_accuracy: 0.7082\n",
            "Epoch 547/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.7768 - val_loss: 0.8452 - val_accuracy: 0.7038\n",
            "Epoch 548/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.7668 - val_loss: 0.8315 - val_accuracy: 0.7099\n",
            "Epoch 549/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.7676 - val_loss: 0.8186 - val_accuracy: 0.7091\n",
            "Epoch 550/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.7779 - val_loss: 0.8292 - val_accuracy: 0.6986\n",
            "Epoch 551/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3818 - accuracy: 0.7753 - val_loss: 0.8485 - val_accuracy: 0.7003\n",
            "Epoch 552/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3888 - accuracy: 0.7811 - val_loss: 0.8440 - val_accuracy: 0.7064\n",
            "Epoch 553/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.7803 - val_loss: 0.8544 - val_accuracy: 0.7056\n",
            "Epoch 554/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.7787 - val_loss: 0.8549 - val_accuracy: 0.7047\n",
            "Epoch 555/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3970 - accuracy: 0.7685 - val_loss: 0.8437 - val_accuracy: 0.7003\n",
            "Epoch 556/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3886 - accuracy: 0.7803 - val_loss: 0.8402 - val_accuracy: 0.6960\n",
            "Epoch 557/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.7740 - val_loss: 0.8559 - val_accuracy: 0.7030\n",
            "Epoch 558/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.7744 - val_loss: 0.8762 - val_accuracy: 0.7064\n",
            "Epoch 559/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3958 - accuracy: 0.7659 - val_loss: 0.8666 - val_accuracy: 0.7030\n",
            "Epoch 560/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.7683 - val_loss: 0.8662 - val_accuracy: 0.7117\n",
            "Epoch 561/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3980 - accuracy: 0.7744 - val_loss: 0.8415 - val_accuracy: 0.7117\n",
            "Epoch 562/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3927 - accuracy: 0.7774 - val_loss: 0.8347 - val_accuracy: 0.6934\n",
            "Epoch 563/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.7750 - val_loss: 0.8324 - val_accuracy: 0.7012\n",
            "Epoch 564/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.7735 - val_loss: 0.8205 - val_accuracy: 0.7030\n",
            "Epoch 565/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.7703 - val_loss: 0.8163 - val_accuracy: 0.6969\n",
            "Epoch 566/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4014 - accuracy: 0.7766 - val_loss: 0.8193 - val_accuracy: 0.6951\n",
            "Epoch 567/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.7777 - val_loss: 0.8130 - val_accuracy: 0.7012\n",
            "Epoch 568/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4084 - accuracy: 0.7622 - val_loss: 0.8050 - val_accuracy: 0.7117\n",
            "Epoch 569/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3779 - accuracy: 0.7816 - val_loss: 0.8188 - val_accuracy: 0.7082\n",
            "Epoch 570/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3986 - accuracy: 0.7737 - val_loss: 0.8047 - val_accuracy: 0.6925\n",
            "Epoch 571/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3981 - accuracy: 0.7676 - val_loss: 0.8075 - val_accuracy: 0.6908\n",
            "Epoch 572/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.7711 - val_loss: 0.8127 - val_accuracy: 0.6977\n",
            "Epoch 573/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.7694 - val_loss: 0.8165 - val_accuracy: 0.6977\n",
            "Epoch 574/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.7779 - val_loss: 0.8052 - val_accuracy: 0.7021\n",
            "Epoch 575/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4012 - accuracy: 0.7639 - val_loss: 0.8081 - val_accuracy: 0.7160\n",
            "Epoch 576/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3928 - accuracy: 0.7735 - val_loss: 0.8130 - val_accuracy: 0.7038\n",
            "Epoch 577/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3829 - accuracy: 0.7768 - val_loss: 0.8299 - val_accuracy: 0.7108\n",
            "Epoch 578/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.7711 - val_loss: 0.8322 - val_accuracy: 0.7082\n",
            "Epoch 579/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.7831 - val_loss: 0.8412 - val_accuracy: 0.7073\n",
            "Epoch 580/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3923 - accuracy: 0.7740 - val_loss: 0.8483 - val_accuracy: 0.7099\n",
            "Epoch 581/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.7759 - val_loss: 0.8464 - val_accuracy: 0.7108\n",
            "Epoch 582/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.7737 - val_loss: 0.8433 - val_accuracy: 0.7064\n",
            "Epoch 583/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.7650 - val_loss: 0.8192 - val_accuracy: 0.7047\n",
            "Epoch 584/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.7718 - val_loss: 0.8094 - val_accuracy: 0.7030\n",
            "Epoch 585/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.7633 - val_loss: 0.8340 - val_accuracy: 0.7021\n",
            "Epoch 586/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.7639 - val_loss: 0.8269 - val_accuracy: 0.6960\n",
            "Epoch 587/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3866 - accuracy: 0.7766 - val_loss: 0.8332 - val_accuracy: 0.7030\n",
            "Epoch 588/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.7740 - val_loss: 0.8350 - val_accuracy: 0.6995\n",
            "Epoch 589/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3834 - accuracy: 0.7772 - val_loss: 0.8293 - val_accuracy: 0.7012\n",
            "Epoch 590/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.7720 - val_loss: 0.8339 - val_accuracy: 0.7021\n",
            "Epoch 591/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.7705 - val_loss: 0.8261 - val_accuracy: 0.7038\n",
            "Epoch 592/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.7720 - val_loss: 0.8303 - val_accuracy: 0.6977\n",
            "Epoch 593/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.7724 - val_loss: 0.8445 - val_accuracy: 0.7047\n",
            "Epoch 594/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.7740 - val_loss: 0.8468 - val_accuracy: 0.6960\n",
            "Epoch 595/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.7666 - val_loss: 0.8471 - val_accuracy: 0.6986\n",
            "Epoch 596/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.7781 - val_loss: 0.8399 - val_accuracy: 0.7003\n",
            "Epoch 597/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.7838 - val_loss: 0.8503 - val_accuracy: 0.6986\n",
            "Epoch 598/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.7689 - val_loss: 0.8522 - val_accuracy: 0.7091\n",
            "Epoch 599/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.7750 - val_loss: 0.8605 - val_accuracy: 0.7021\n",
            "Epoch 600/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.7757 - val_loss: 0.8487 - val_accuracy: 0.6943\n",
            "Epoch 601/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.7672 - val_loss: 0.8415 - val_accuracy: 0.6951\n",
            "Epoch 602/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3731 - accuracy: 0.7755 - val_loss: 0.8584 - val_accuracy: 0.7099\n",
            "Epoch 603/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.7774 - val_loss: 0.8522 - val_accuracy: 0.7038\n",
            "Epoch 604/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3927 - accuracy: 0.7726 - val_loss: 0.8417 - val_accuracy: 0.6969\n",
            "Epoch 605/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.7744 - val_loss: 0.8330 - val_accuracy: 0.7003\n",
            "Epoch 606/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.7783 - val_loss: 0.8435 - val_accuracy: 0.6916\n",
            "Epoch 607/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.7661 - val_loss: 0.8270 - val_accuracy: 0.7030\n",
            "Epoch 608/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.7792 - val_loss: 0.8369 - val_accuracy: 0.7021\n",
            "Epoch 609/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.7750 - val_loss: 0.8334 - val_accuracy: 0.6960\n",
            "Epoch 610/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.7700 - val_loss: 0.8306 - val_accuracy: 0.6925\n",
            "Epoch 611/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.7685 - val_loss: 0.8248 - val_accuracy: 0.6890\n",
            "Epoch 612/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3779 - accuracy: 0.7796 - val_loss: 0.8238 - val_accuracy: 0.6925\n",
            "Epoch 613/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.7652 - val_loss: 0.8292 - val_accuracy: 0.6916\n",
            "Epoch 614/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.7663 - val_loss: 0.8387 - val_accuracy: 0.6986\n",
            "Epoch 615/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.7650 - val_loss: 0.8377 - val_accuracy: 0.6995\n",
            "Epoch 616/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3768 - accuracy: 0.7670 - val_loss: 0.8557 - val_accuracy: 0.7056\n",
            "Epoch 617/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.7679 - val_loss: 0.8643 - val_accuracy: 0.7143\n",
            "Epoch 618/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.7787 - val_loss: 0.8477 - val_accuracy: 0.7073\n",
            "Epoch 619/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.7713 - val_loss: 0.8633 - val_accuracy: 0.7064\n",
            "Epoch 620/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.7722 - val_loss: 0.8501 - val_accuracy: 0.6934\n",
            "Epoch 621/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.7729 - val_loss: 0.8662 - val_accuracy: 0.7012\n",
            "Epoch 622/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4051 - accuracy: 0.7676 - val_loss: 0.8490 - val_accuracy: 0.7003\n",
            "Epoch 623/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.7692 - val_loss: 0.8520 - val_accuracy: 0.7117\n",
            "Epoch 624/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.7811 - val_loss: 0.8488 - val_accuracy: 0.7160\n",
            "Epoch 625/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.7666 - val_loss: 0.8529 - val_accuracy: 0.7186\n",
            "Epoch 626/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.7729 - val_loss: 0.8503 - val_accuracy: 0.7152\n",
            "Epoch 627/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.7820 - val_loss: 0.8514 - val_accuracy: 0.7178\n",
            "Epoch 628/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.7735 - val_loss: 0.8578 - val_accuracy: 0.7073\n",
            "Epoch 629/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3848 - accuracy: 0.7805 - val_loss: 0.8409 - val_accuracy: 0.7143\n",
            "Epoch 630/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.7816 - val_loss: 0.8404 - val_accuracy: 0.7152\n",
            "Epoch 631/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.7772 - val_loss: 0.8383 - val_accuracy: 0.7073\n",
            "Epoch 632/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.7705 - val_loss: 0.8402 - val_accuracy: 0.7038\n",
            "Epoch 633/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3834 - accuracy: 0.7803 - val_loss: 0.8255 - val_accuracy: 0.6995\n",
            "Epoch 634/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3981 - accuracy: 0.7764 - val_loss: 0.8075 - val_accuracy: 0.6943\n",
            "Epoch 635/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3988 - accuracy: 0.7663 - val_loss: 0.8033 - val_accuracy: 0.6934\n",
            "Epoch 636/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.7646 - val_loss: 0.8013 - val_accuracy: 0.7108\n",
            "Epoch 637/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.7726 - val_loss: 0.8138 - val_accuracy: 0.7152\n",
            "Epoch 638/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3765 - accuracy: 0.7794 - val_loss: 0.8232 - val_accuracy: 0.7125\n",
            "Epoch 639/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.7744 - val_loss: 0.8160 - val_accuracy: 0.7056\n",
            "Epoch 640/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.7659 - val_loss: 0.8063 - val_accuracy: 0.7064\n",
            "Epoch 641/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3829 - accuracy: 0.7692 - val_loss: 0.8126 - val_accuracy: 0.7064\n",
            "Epoch 642/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3882 - accuracy: 0.7692 - val_loss: 0.8139 - val_accuracy: 0.7047\n",
            "Epoch 643/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.7707 - val_loss: 0.8248 - val_accuracy: 0.7073\n",
            "Epoch 644/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.7694 - val_loss: 0.8031 - val_accuracy: 0.7064\n",
            "Epoch 645/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.7692 - val_loss: 0.8096 - val_accuracy: 0.7099\n",
            "Epoch 646/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3837 - accuracy: 0.7716 - val_loss: 0.8166 - val_accuracy: 0.7099\n",
            "Epoch 647/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3944 - accuracy: 0.7642 - val_loss: 0.8088 - val_accuracy: 0.6995\n",
            "Epoch 648/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.7657 - val_loss: 0.7889 - val_accuracy: 0.6995\n",
            "Epoch 649/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.7753 - val_loss: 0.8185 - val_accuracy: 0.7012\n",
            "Epoch 650/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3964 - accuracy: 0.7635 - val_loss: 0.8267 - val_accuracy: 0.7012\n",
            "Epoch 651/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.7740 - val_loss: 0.8194 - val_accuracy: 0.7003\n",
            "Epoch 652/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.7611 - val_loss: 0.8079 - val_accuracy: 0.7064\n",
            "Epoch 653/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3831 - accuracy: 0.7718 - val_loss: 0.8137 - val_accuracy: 0.6986\n",
            "Epoch 654/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.7679 - val_loss: 0.8174 - val_accuracy: 0.7021\n",
            "Epoch 655/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.7622 - val_loss: 0.8192 - val_accuracy: 0.6969\n",
            "Epoch 656/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.7713 - val_loss: 0.8388 - val_accuracy: 0.6995\n",
            "Epoch 657/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.7661 - val_loss: 0.8116 - val_accuracy: 0.7030\n",
            "Epoch 658/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.7646 - val_loss: 0.8164 - val_accuracy: 0.7012\n",
            "Epoch 659/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3928 - accuracy: 0.7648 - val_loss: 0.8161 - val_accuracy: 0.6986\n",
            "Epoch 660/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.7661 - val_loss: 0.8274 - val_accuracy: 0.6977\n",
            "Epoch 661/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.7735 - val_loss: 0.8433 - val_accuracy: 0.6908\n",
            "Epoch 662/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3853 - accuracy: 0.7735 - val_loss: 0.8497 - val_accuracy: 0.6977\n",
            "Epoch 663/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.7679 - val_loss: 0.8421 - val_accuracy: 0.7030\n",
            "Epoch 664/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.7609 - val_loss: 0.8300 - val_accuracy: 0.7021\n",
            "Epoch 665/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3837 - accuracy: 0.7644 - val_loss: 0.8330 - val_accuracy: 0.7030\n",
            "Epoch 666/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.7709 - val_loss: 0.8198 - val_accuracy: 0.6986\n",
            "Epoch 667/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.7720 - val_loss: 0.8287 - val_accuracy: 0.7125\n",
            "Epoch 668/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.7779 - val_loss: 0.8457 - val_accuracy: 0.7143\n",
            "Epoch 669/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.7757 - val_loss: 0.8523 - val_accuracy: 0.7178\n",
            "Epoch 670/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.7783 - val_loss: 0.8322 - val_accuracy: 0.7125\n",
            "Epoch 671/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.7764 - val_loss: 0.8133 - val_accuracy: 0.7038\n",
            "Epoch 672/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.7753 - val_loss: 0.8184 - val_accuracy: 0.7047\n",
            "Epoch 673/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.7768 - val_loss: 0.8063 - val_accuracy: 0.7012\n",
            "Epoch 674/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.7692 - val_loss: 0.8041 - val_accuracy: 0.6934\n",
            "Epoch 675/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.7655 - val_loss: 0.8075 - val_accuracy: 0.6960\n",
            "Epoch 676/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4019 - accuracy: 0.7668 - val_loss: 0.7999 - val_accuracy: 0.6960\n",
            "Epoch 677/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.7666 - val_loss: 0.8220 - val_accuracy: 0.7047\n",
            "Epoch 678/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3786 - accuracy: 0.7777 - val_loss: 0.8066 - val_accuracy: 0.6890\n",
            "Epoch 679/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3932 - accuracy: 0.7552 - val_loss: 0.7983 - val_accuracy: 0.6934\n",
            "Epoch 680/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.7718 - val_loss: 0.8064 - val_accuracy: 0.6960\n",
            "Epoch 681/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.7602 - val_loss: 0.8119 - val_accuracy: 0.6951\n",
            "Epoch 682/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.7659 - val_loss: 0.8159 - val_accuracy: 0.6934\n",
            "Epoch 683/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3872 - accuracy: 0.7750 - val_loss: 0.8233 - val_accuracy: 0.7030\n",
            "Epoch 684/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3830 - accuracy: 0.7646 - val_loss: 0.8389 - val_accuracy: 0.7056\n",
            "Epoch 685/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.7840 - val_loss: 0.8539 - val_accuracy: 0.7056\n",
            "Epoch 686/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3946 - accuracy: 0.7657 - val_loss: 0.8553 - val_accuracy: 0.7091\n",
            "Epoch 687/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.7753 - val_loss: 0.8544 - val_accuracy: 0.7099\n",
            "Epoch 688/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3887 - accuracy: 0.7742 - val_loss: 0.8484 - val_accuracy: 0.7125\n",
            "Epoch 689/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3857 - accuracy: 0.7753 - val_loss: 0.8350 - val_accuracy: 0.7030\n",
            "Epoch 690/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3769 - accuracy: 0.7742 - val_loss: 0.8383 - val_accuracy: 0.7030\n",
            "Epoch 691/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.7644 - val_loss: 0.8351 - val_accuracy: 0.7038\n",
            "Epoch 692/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3870 - accuracy: 0.7683 - val_loss: 0.8292 - val_accuracy: 0.7003\n",
            "Epoch 693/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.7659 - val_loss: 0.8396 - val_accuracy: 0.6934\n",
            "Epoch 694/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.7642 - val_loss: 0.8414 - val_accuracy: 0.6925\n",
            "Epoch 695/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3875 - accuracy: 0.7718 - val_loss: 0.8421 - val_accuracy: 0.6873\n",
            "Epoch 696/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.7628 - val_loss: 0.8655 - val_accuracy: 0.6960\n",
            "Epoch 697/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.7698 - val_loss: 0.8810 - val_accuracy: 0.6925\n",
            "Epoch 698/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.7768 - val_loss: 0.8771 - val_accuracy: 0.7003\n",
            "Epoch 699/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3803 - accuracy: 0.7740 - val_loss: 0.8926 - val_accuracy: 0.7082\n",
            "Epoch 700/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.7685 - val_loss: 0.8734 - val_accuracy: 0.7099\n",
            "Epoch 701/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3974 - accuracy: 0.7628 - val_loss: 0.8597 - val_accuracy: 0.7038\n",
            "Epoch 702/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3902 - accuracy: 0.7692 - val_loss: 0.8500 - val_accuracy: 0.7073\n",
            "Epoch 703/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3988 - accuracy: 0.7700 - val_loss: 0.8664 - val_accuracy: 0.7099\n",
            "Epoch 704/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3869 - accuracy: 0.7703 - val_loss: 0.8460 - val_accuracy: 0.7056\n",
            "Epoch 705/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3864 - accuracy: 0.7681 - val_loss: 0.8427 - val_accuracy: 0.7003\n",
            "Epoch 706/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3933 - accuracy: 0.7781 - val_loss: 0.8407 - val_accuracy: 0.7047\n",
            "Epoch 707/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3873 - accuracy: 0.7814 - val_loss: 0.8180 - val_accuracy: 0.7047\n",
            "Epoch 708/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3974 - accuracy: 0.7670 - val_loss: 0.8150 - val_accuracy: 0.7091\n",
            "Epoch 709/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.7666 - val_loss: 0.8174 - val_accuracy: 0.7056\n",
            "Epoch 710/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3913 - accuracy: 0.7770 - val_loss: 0.8235 - val_accuracy: 0.7047\n",
            "Epoch 711/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.7844 - val_loss: 0.8459 - val_accuracy: 0.7056\n",
            "Epoch 712/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.7740 - val_loss: 0.8490 - val_accuracy: 0.7056\n",
            "Epoch 713/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.7807 - val_loss: 0.8466 - val_accuracy: 0.7195\n",
            "Epoch 714/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.7698 - val_loss: 0.8329 - val_accuracy: 0.7178\n",
            "Epoch 715/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3944 - accuracy: 0.7733 - val_loss: 0.8380 - val_accuracy: 0.7152\n",
            "Epoch 716/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.7848 - val_loss: 0.8416 - val_accuracy: 0.7178\n",
            "Epoch 717/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3848 - accuracy: 0.7787 - val_loss: 0.8494 - val_accuracy: 0.7038\n",
            "Epoch 718/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3944 - accuracy: 0.7790 - val_loss: 0.8392 - val_accuracy: 0.6995\n",
            "Epoch 719/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.7707 - val_loss: 0.8599 - val_accuracy: 0.6977\n",
            "Epoch 720/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.7622 - val_loss: 0.8398 - val_accuracy: 0.7038\n",
            "Epoch 721/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3902 - accuracy: 0.7796 - val_loss: 0.8289 - val_accuracy: 0.6960\n",
            "Epoch 722/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.7746 - val_loss: 0.8156 - val_accuracy: 0.6960\n",
            "Epoch 723/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3831 - accuracy: 0.7777 - val_loss: 0.8140 - val_accuracy: 0.6943\n",
            "Epoch 724/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3942 - accuracy: 0.7622 - val_loss: 0.8129 - val_accuracy: 0.6908\n",
            "Epoch 725/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3902 - accuracy: 0.7663 - val_loss: 0.8312 - val_accuracy: 0.6899\n",
            "Epoch 726/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3751 - accuracy: 0.7798 - val_loss: 0.8378 - val_accuracy: 0.6934\n",
            "Epoch 727/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3813 - accuracy: 0.7735 - val_loss: 0.8382 - val_accuracy: 0.6969\n",
            "Epoch 728/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.7774 - val_loss: 0.8499 - val_accuracy: 0.7030\n",
            "Epoch 729/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.7694 - val_loss: 0.8343 - val_accuracy: 0.6969\n",
            "Epoch 730/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3891 - accuracy: 0.7753 - val_loss: 0.8503 - val_accuracy: 0.6943\n",
            "Epoch 731/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.7646 - val_loss: 0.8591 - val_accuracy: 0.6995\n",
            "Epoch 732/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.7666 - val_loss: 0.8532 - val_accuracy: 0.7003\n",
            "Epoch 733/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.7750 - val_loss: 0.8633 - val_accuracy: 0.7012\n",
            "Epoch 734/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3906 - accuracy: 0.7713 - val_loss: 0.8608 - val_accuracy: 0.7021\n",
            "Epoch 735/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.7683 - val_loss: 0.8409 - val_accuracy: 0.6969\n",
            "Epoch 736/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3994 - accuracy: 0.7642 - val_loss: 0.8528 - val_accuracy: 0.7012\n",
            "Epoch 737/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3756 - accuracy: 0.7770 - val_loss: 0.8490 - val_accuracy: 0.7021\n",
            "Epoch 738/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.7683 - val_loss: 0.8596 - val_accuracy: 0.7143\n",
            "Epoch 739/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.7711 - val_loss: 0.8516 - val_accuracy: 0.7056\n",
            "Epoch 740/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.7811 - val_loss: 0.8585 - val_accuracy: 0.7073\n",
            "Epoch 741/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.7790 - val_loss: 0.8551 - val_accuracy: 0.7012\n",
            "Epoch 742/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.7735 - val_loss: 0.8540 - val_accuracy: 0.7056\n",
            "Epoch 743/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.7766 - val_loss: 0.8427 - val_accuracy: 0.7038\n",
            "Epoch 744/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3860 - accuracy: 0.7733 - val_loss: 0.8348 - val_accuracy: 0.7056\n",
            "Epoch 745/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3932 - accuracy: 0.7698 - val_loss: 0.8315 - val_accuracy: 0.6951\n",
            "Epoch 746/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.7759 - val_loss: 0.8523 - val_accuracy: 0.6995\n",
            "Epoch 747/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.7796 - val_loss: 0.8490 - val_accuracy: 0.6943\n",
            "Epoch 748/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3855 - accuracy: 0.7757 - val_loss: 0.8431 - val_accuracy: 0.6951\n",
            "Epoch 749/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3837 - accuracy: 0.7724 - val_loss: 0.8526 - val_accuracy: 0.6977\n",
            "Epoch 750/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.7735 - val_loss: 0.8607 - val_accuracy: 0.7030\n",
            "Epoch 751/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3798 - accuracy: 0.7764 - val_loss: 0.8640 - val_accuracy: 0.7073\n",
            "Epoch 752/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.7755 - val_loss: 0.8328 - val_accuracy: 0.6882\n",
            "Epoch 753/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3836 - accuracy: 0.7746 - val_loss: 0.8407 - val_accuracy: 0.6925\n",
            "Epoch 754/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.7774 - val_loss: 0.8591 - val_accuracy: 0.6943\n",
            "Epoch 755/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.7768 - val_loss: 0.8695 - val_accuracy: 0.6977\n",
            "Epoch 756/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3740 - accuracy: 0.7779 - val_loss: 0.8748 - val_accuracy: 0.7012\n",
            "Epoch 757/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.7679 - val_loss: 0.8722 - val_accuracy: 0.6960\n",
            "Epoch 758/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.7683 - val_loss: 0.8444 - val_accuracy: 0.6899\n",
            "Epoch 759/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3890 - accuracy: 0.7655 - val_loss: 0.8450 - val_accuracy: 0.6873\n",
            "Epoch 760/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.7613 - val_loss: 0.8610 - val_accuracy: 0.6925\n",
            "Epoch 761/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3868 - accuracy: 0.7628 - val_loss: 0.8526 - val_accuracy: 0.7021\n",
            "Epoch 762/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.7685 - val_loss: 0.8605 - val_accuracy: 0.6934\n",
            "Epoch 763/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3926 - accuracy: 0.7591 - val_loss: 0.8745 - val_accuracy: 0.6943\n",
            "Epoch 764/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.7689 - val_loss: 0.8743 - val_accuracy: 0.6943\n",
            "Epoch 765/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.7694 - val_loss: 0.8747 - val_accuracy: 0.6977\n",
            "Epoch 766/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.7716 - val_loss: 0.8807 - val_accuracy: 0.7082\n",
            "Epoch 767/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3809 - accuracy: 0.7726 - val_loss: 0.8664 - val_accuracy: 0.7056\n",
            "Epoch 768/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.7676 - val_loss: 0.8790 - val_accuracy: 0.7073\n",
            "Epoch 769/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.7777 - val_loss: 0.8690 - val_accuracy: 0.7003\n",
            "Epoch 770/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3977 - accuracy: 0.7672 - val_loss: 0.8534 - val_accuracy: 0.6951\n",
            "Epoch 771/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3868 - accuracy: 0.7666 - val_loss: 0.8579 - val_accuracy: 0.6969\n",
            "Epoch 772/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.7683 - val_loss: 0.8561 - val_accuracy: 0.6960\n",
            "Epoch 773/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3895 - accuracy: 0.7628 - val_loss: 0.8348 - val_accuracy: 0.6969\n",
            "Epoch 774/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3881 - accuracy: 0.7709 - val_loss: 0.8359 - val_accuracy: 0.6986\n",
            "Epoch 775/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3868 - accuracy: 0.7750 - val_loss: 0.8355 - val_accuracy: 0.6995\n",
            "Epoch 776/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3961 - accuracy: 0.7628 - val_loss: 0.8221 - val_accuracy: 0.6969\n",
            "Epoch 777/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3883 - accuracy: 0.7644 - val_loss: 0.8366 - val_accuracy: 0.7003\n",
            "Epoch 778/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3883 - accuracy: 0.7633 - val_loss: 0.8619 - val_accuracy: 0.7047\n",
            "Epoch 779/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3840 - accuracy: 0.7720 - val_loss: 0.8665 - val_accuracy: 0.7117\n",
            "Epoch 780/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3894 - accuracy: 0.7696 - val_loss: 0.8507 - val_accuracy: 0.7125\n",
            "Epoch 781/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3858 - accuracy: 0.7711 - val_loss: 0.8468 - val_accuracy: 0.7003\n",
            "Epoch 782/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3830 - accuracy: 0.7705 - val_loss: 0.8461 - val_accuracy: 0.7003\n",
            "Epoch 783/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3874 - accuracy: 0.7742 - val_loss: 0.8628 - val_accuracy: 0.7030\n",
            "Epoch 784/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3837 - accuracy: 0.7576 - val_loss: 0.8623 - val_accuracy: 0.7038\n",
            "Epoch 785/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3834 - accuracy: 0.7672 - val_loss: 0.8621 - val_accuracy: 0.6995\n",
            "Epoch 786/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.7663 - val_loss: 0.8508 - val_accuracy: 0.6977\n",
            "Epoch 787/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3901 - accuracy: 0.7620 - val_loss: 0.8574 - val_accuracy: 0.6986\n",
            "Epoch 788/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.7733 - val_loss: 0.8691 - val_accuracy: 0.7003\n",
            "Epoch 789/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3894 - accuracy: 0.7659 - val_loss: 0.8552 - val_accuracy: 0.6986\n",
            "Epoch 790/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.7657 - val_loss: 0.8727 - val_accuracy: 0.7056\n",
            "Epoch 791/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3944 - accuracy: 0.7735 - val_loss: 0.8686 - val_accuracy: 0.6977\n",
            "Epoch 792/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3934 - accuracy: 0.7722 - val_loss: 0.8794 - val_accuracy: 0.7021\n",
            "Epoch 793/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3905 - accuracy: 0.7685 - val_loss: 0.8463 - val_accuracy: 0.6977\n",
            "Epoch 794/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.7644 - val_loss: 0.8400 - val_accuracy: 0.6934\n",
            "Epoch 795/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3814 - accuracy: 0.7718 - val_loss: 0.8473 - val_accuracy: 0.6925\n",
            "Epoch 796/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.7777 - val_loss: 0.8669 - val_accuracy: 0.6995\n",
            "Epoch 797/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3811 - accuracy: 0.7774 - val_loss: 0.8746 - val_accuracy: 0.6969\n",
            "Epoch 798/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3837 - accuracy: 0.7650 - val_loss: 0.8841 - val_accuracy: 0.6977\n",
            "Epoch 799/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3907 - accuracy: 0.7646 - val_loss: 0.8907 - val_accuracy: 0.6986\n",
            "Epoch 800/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3847 - accuracy: 0.7801 - val_loss: 0.8823 - val_accuracy: 0.6934\n",
            "Epoch 801/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4004 - accuracy: 0.7711 - val_loss: 0.8383 - val_accuracy: 0.6934\n",
            "Epoch 802/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3909 - accuracy: 0.7670 - val_loss: 0.8496 - val_accuracy: 0.7012\n",
            "Epoch 803/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3783 - accuracy: 0.7796 - val_loss: 0.8527 - val_accuracy: 0.7003\n",
            "Epoch 804/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3870 - accuracy: 0.7676 - val_loss: 0.8646 - val_accuracy: 0.7030\n",
            "Epoch 805/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3954 - accuracy: 0.7724 - val_loss: 0.8649 - val_accuracy: 0.7073\n",
            "Epoch 806/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3841 - accuracy: 0.7755 - val_loss: 0.8624 - val_accuracy: 0.7047\n",
            "Epoch 807/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4112 - accuracy: 0.7598 - val_loss: 0.8387 - val_accuracy: 0.6977\n",
            "Epoch 808/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.7737 - val_loss: 0.8353 - val_accuracy: 0.6960\n",
            "Epoch 809/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3810 - accuracy: 0.7794 - val_loss: 0.8348 - val_accuracy: 0.7012\n",
            "Epoch 810/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.7639 - val_loss: 0.8519 - val_accuracy: 0.6977\n",
            "Epoch 811/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3902 - accuracy: 0.7703 - val_loss: 0.8561 - val_accuracy: 0.7012\n",
            "Epoch 812/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3825 - accuracy: 0.7713 - val_loss: 0.8651 - val_accuracy: 0.6995\n",
            "Epoch 813/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3985 - accuracy: 0.7620 - val_loss: 0.8529 - val_accuracy: 0.6890\n",
            "Epoch 814/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3955 - accuracy: 0.7646 - val_loss: 0.8618 - val_accuracy: 0.6943\n",
            "Epoch 815/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3818 - accuracy: 0.7687 - val_loss: 0.8610 - val_accuracy: 0.7012\n",
            "Epoch 816/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.7687 - val_loss: 0.8687 - val_accuracy: 0.7030\n",
            "Epoch 817/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.7731 - val_loss: 0.8793 - val_accuracy: 0.7021\n",
            "Epoch 818/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3852 - accuracy: 0.7703 - val_loss: 0.8456 - val_accuracy: 0.6977\n",
            "Epoch 819/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3867 - accuracy: 0.7681 - val_loss: 0.8364 - val_accuracy: 0.7012\n",
            "Epoch 820/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.7713 - val_loss: 0.8492 - val_accuracy: 0.6995\n",
            "Epoch 821/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3732 - accuracy: 0.7726 - val_loss: 0.8634 - val_accuracy: 0.7021\n",
            "Epoch 822/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3918 - accuracy: 0.7768 - val_loss: 0.8546 - val_accuracy: 0.7012\n",
            "Epoch 823/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.7781 - val_loss: 0.8511 - val_accuracy: 0.7012\n",
            "Epoch 824/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.7753 - val_loss: 0.8474 - val_accuracy: 0.7038\n",
            "Epoch 825/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.7718 - val_loss: 0.8503 - val_accuracy: 0.7108\n",
            "Epoch 826/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.7724 - val_loss: 0.8574 - val_accuracy: 0.7056\n",
            "Epoch 827/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.7755 - val_loss: 0.8746 - val_accuracy: 0.7091\n",
            "Epoch 828/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.7768 - val_loss: 0.8409 - val_accuracy: 0.6960\n",
            "Epoch 829/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3841 - accuracy: 0.7711 - val_loss: 0.8547 - val_accuracy: 0.7047\n",
            "Epoch 830/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.7685 - val_loss: 0.8557 - val_accuracy: 0.7099\n",
            "Epoch 831/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3782 - accuracy: 0.7787 - val_loss: 0.8615 - val_accuracy: 0.6969\n",
            "Epoch 832/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3785 - accuracy: 0.7783 - val_loss: 0.8452 - val_accuracy: 0.6890\n",
            "Epoch 833/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.7744 - val_loss: 0.8428 - val_accuracy: 0.6899\n",
            "Epoch 834/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3861 - accuracy: 0.7681 - val_loss: 0.8519 - val_accuracy: 0.6934\n",
            "Epoch 835/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3745 - accuracy: 0.7740 - val_loss: 0.8445 - val_accuracy: 0.6943\n",
            "Epoch 836/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3949 - accuracy: 0.7733 - val_loss: 0.8536 - val_accuracy: 0.7030\n",
            "Epoch 837/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3829 - accuracy: 0.7742 - val_loss: 0.8438 - val_accuracy: 0.6960\n",
            "Epoch 838/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3916 - accuracy: 0.7644 - val_loss: 0.8596 - val_accuracy: 0.7056\n",
            "Epoch 839/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3864 - accuracy: 0.7731 - val_loss: 0.8574 - val_accuracy: 0.7073\n",
            "Epoch 840/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3776 - accuracy: 0.7766 - val_loss: 0.8394 - val_accuracy: 0.7047\n",
            "Epoch 841/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.7735 - val_loss: 0.8437 - val_accuracy: 0.7064\n",
            "Epoch 842/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3797 - accuracy: 0.7737 - val_loss: 0.8557 - val_accuracy: 0.7082\n",
            "Epoch 843/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3743 - accuracy: 0.7798 - val_loss: 0.8561 - val_accuracy: 0.6995\n",
            "Epoch 844/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3789 - accuracy: 0.7779 - val_loss: 0.8583 - val_accuracy: 0.7021\n",
            "Epoch 845/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3724 - accuracy: 0.7827 - val_loss: 0.8648 - val_accuracy: 0.7030\n",
            "Epoch 846/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.7750 - val_loss: 0.8887 - val_accuracy: 0.6995\n",
            "Epoch 847/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3814 - accuracy: 0.7770 - val_loss: 0.8680 - val_accuracy: 0.7003\n",
            "Epoch 848/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3871 - accuracy: 0.7703 - val_loss: 0.8608 - val_accuracy: 0.6943\n",
            "Epoch 849/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3839 - accuracy: 0.7670 - val_loss: 0.8406 - val_accuracy: 0.6882\n",
            "Epoch 850/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3786 - accuracy: 0.7694 - val_loss: 0.8384 - val_accuracy: 0.6873\n",
            "Epoch 851/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3891 - accuracy: 0.7676 - val_loss: 0.8526 - val_accuracy: 0.6855\n",
            "Epoch 852/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3737 - accuracy: 0.7698 - val_loss: 0.8736 - val_accuracy: 0.6890\n",
            "Epoch 853/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3821 - accuracy: 0.7692 - val_loss: 0.8689 - val_accuracy: 0.6882\n",
            "Epoch 854/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3849 - accuracy: 0.7726 - val_loss: 0.8879 - val_accuracy: 0.6916\n",
            "Epoch 855/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3839 - accuracy: 0.7661 - val_loss: 0.8859 - val_accuracy: 0.6925\n",
            "Epoch 856/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.7703 - val_loss: 0.8526 - val_accuracy: 0.6864\n",
            "Epoch 857/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3987 - accuracy: 0.7624 - val_loss: 0.8512 - val_accuracy: 0.6882\n",
            "Epoch 858/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.7666 - val_loss: 0.8647 - val_accuracy: 0.6934\n",
            "Epoch 859/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.7724 - val_loss: 0.8449 - val_accuracy: 0.6890\n",
            "Epoch 860/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3851 - accuracy: 0.7729 - val_loss: 0.8671 - val_accuracy: 0.6969\n",
            "Epoch 861/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3720 - accuracy: 0.7829 - val_loss: 0.8886 - val_accuracy: 0.6986\n",
            "Epoch 862/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.7820 - val_loss: 0.8643 - val_accuracy: 0.6969\n",
            "Epoch 863/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.7822 - val_loss: 0.8666 - val_accuracy: 0.6986\n",
            "Epoch 864/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3856 - accuracy: 0.7774 - val_loss: 0.8594 - val_accuracy: 0.6969\n",
            "Epoch 865/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3777 - accuracy: 0.7753 - val_loss: 0.8725 - val_accuracy: 0.6986\n",
            "Epoch 866/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3825 - accuracy: 0.7705 - val_loss: 0.8465 - val_accuracy: 0.6977\n",
            "Epoch 867/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3829 - accuracy: 0.7783 - val_loss: 0.8579 - val_accuracy: 0.6951\n",
            "Epoch 868/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3806 - accuracy: 0.7733 - val_loss: 0.8680 - val_accuracy: 0.7030\n",
            "Epoch 869/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.7703 - val_loss: 0.8467 - val_accuracy: 0.6908\n",
            "Epoch 870/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3887 - accuracy: 0.7683 - val_loss: 0.8396 - val_accuracy: 0.6899\n",
            "Epoch 871/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3713 - accuracy: 0.7781 - val_loss: 0.8788 - val_accuracy: 0.6960\n",
            "Epoch 872/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.7622 - val_loss: 0.8581 - val_accuracy: 0.6916\n",
            "Epoch 873/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3836 - accuracy: 0.7740 - val_loss: 0.8523 - val_accuracy: 0.6943\n",
            "Epoch 874/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3911 - accuracy: 0.7705 - val_loss: 0.8504 - val_accuracy: 0.6829\n",
            "Epoch 875/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3884 - accuracy: 0.7628 - val_loss: 0.8600 - val_accuracy: 0.6890\n",
            "Epoch 876/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3838 - accuracy: 0.7716 - val_loss: 0.8682 - val_accuracy: 0.6951\n",
            "Epoch 877/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.7824 - val_loss: 0.8591 - val_accuracy: 0.6969\n",
            "Epoch 878/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3965 - accuracy: 0.7635 - val_loss: 0.8446 - val_accuracy: 0.6882\n",
            "Epoch 879/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.7703 - val_loss: 0.8481 - val_accuracy: 0.6934\n",
            "Epoch 880/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3957 - accuracy: 0.7718 - val_loss: 0.8454 - val_accuracy: 0.6855\n",
            "Epoch 881/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.4005 - accuracy: 0.7611 - val_loss: 0.8452 - val_accuracy: 0.6882\n",
            "Epoch 882/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3826 - accuracy: 0.7753 - val_loss: 0.8702 - val_accuracy: 0.6943\n",
            "Epoch 883/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3799 - accuracy: 0.7716 - val_loss: 0.8863 - val_accuracy: 0.6995\n",
            "Epoch 884/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3894 - accuracy: 0.7689 - val_loss: 0.8582 - val_accuracy: 0.6916\n",
            "Epoch 885/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.7716 - val_loss: 0.8647 - val_accuracy: 0.6969\n",
            "Epoch 886/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3817 - accuracy: 0.7770 - val_loss: 0.8721 - val_accuracy: 0.6986\n",
            "Epoch 887/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3986 - accuracy: 0.7646 - val_loss: 0.8567 - val_accuracy: 0.6908\n",
            "Epoch 888/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3909 - accuracy: 0.7729 - val_loss: 0.8470 - val_accuracy: 0.6916\n",
            "Epoch 889/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3903 - accuracy: 0.7668 - val_loss: 0.8519 - val_accuracy: 0.6916\n",
            "Epoch 890/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3890 - accuracy: 0.7750 - val_loss: 0.8586 - val_accuracy: 0.6873\n",
            "Epoch 891/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3798 - accuracy: 0.7713 - val_loss: 0.8679 - val_accuracy: 0.6977\n",
            "Epoch 892/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3880 - accuracy: 0.7683 - val_loss: 0.8396 - val_accuracy: 0.6829\n",
            "Epoch 893/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3899 - accuracy: 0.7670 - val_loss: 0.8708 - val_accuracy: 0.6960\n",
            "Epoch 894/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3828 - accuracy: 0.7583 - val_loss: 0.8562 - val_accuracy: 0.6890\n",
            "Epoch 895/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.7635 - val_loss: 0.8646 - val_accuracy: 0.6943\n",
            "Epoch 896/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3844 - accuracy: 0.7639 - val_loss: 0.8628 - val_accuracy: 0.6916\n",
            "Epoch 897/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3832 - accuracy: 0.7607 - val_loss: 0.8628 - val_accuracy: 0.6899\n",
            "Epoch 898/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.7628 - val_loss: 0.8531 - val_accuracy: 0.6899\n",
            "Epoch 899/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3934 - accuracy: 0.7600 - val_loss: 0.8643 - val_accuracy: 0.6864\n",
            "Epoch 900/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3942 - accuracy: 0.7703 - val_loss: 0.8394 - val_accuracy: 0.6829\n",
            "Epoch 901/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3889 - accuracy: 0.7668 - val_loss: 0.8519 - val_accuracy: 0.6916\n",
            "Epoch 902/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3933 - accuracy: 0.7624 - val_loss: 0.8589 - val_accuracy: 0.6986\n",
            "Epoch 903/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3930 - accuracy: 0.7659 - val_loss: 0.8657 - val_accuracy: 0.6977\n",
            "Epoch 904/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.7713 - val_loss: 0.8577 - val_accuracy: 0.7012\n",
            "Epoch 905/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.7609 - val_loss: 0.8536 - val_accuracy: 0.7099\n",
            "Epoch 906/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3808 - accuracy: 0.7820 - val_loss: 0.8727 - val_accuracy: 0.7091\n",
            "Epoch 907/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3762 - accuracy: 0.7779 - val_loss: 0.8697 - val_accuracy: 0.6969\n",
            "Epoch 908/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3827 - accuracy: 0.7726 - val_loss: 0.8703 - val_accuracy: 0.7056\n",
            "Epoch 909/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3882 - accuracy: 0.7729 - val_loss: 0.8616 - val_accuracy: 0.7073\n",
            "Epoch 910/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3884 - accuracy: 0.7637 - val_loss: 0.8396 - val_accuracy: 0.7012\n",
            "Epoch 911/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3958 - accuracy: 0.7618 - val_loss: 0.8326 - val_accuracy: 0.6969\n",
            "Epoch 912/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3844 - accuracy: 0.7670 - val_loss: 0.8411 - val_accuracy: 0.6908\n",
            "Epoch 913/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3911 - accuracy: 0.7639 - val_loss: 0.8546 - val_accuracy: 0.6951\n",
            "Epoch 914/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3798 - accuracy: 0.7748 - val_loss: 0.8612 - val_accuracy: 0.6899\n",
            "Epoch 915/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3951 - accuracy: 0.7620 - val_loss: 0.8751 - val_accuracy: 0.7047\n",
            "Epoch 916/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3990 - accuracy: 0.7650 - val_loss: 0.8552 - val_accuracy: 0.7012\n",
            "Epoch 917/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3933 - accuracy: 0.7722 - val_loss: 0.8442 - val_accuracy: 0.6951\n",
            "Epoch 918/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3890 - accuracy: 0.7644 - val_loss: 0.8395 - val_accuracy: 0.6864\n",
            "Epoch 919/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3905 - accuracy: 0.7696 - val_loss: 0.8327 - val_accuracy: 0.6916\n",
            "Epoch 920/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3915 - accuracy: 0.7698 - val_loss: 0.8360 - val_accuracy: 0.6951\n",
            "Epoch 921/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3983 - accuracy: 0.7539 - val_loss: 0.8407 - val_accuracy: 0.6986\n",
            "Epoch 922/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3952 - accuracy: 0.7637 - val_loss: 0.8519 - val_accuracy: 0.6916\n",
            "Epoch 923/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3838 - accuracy: 0.7711 - val_loss: 0.8610 - val_accuracy: 0.7064\n",
            "Epoch 924/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.7657 - val_loss: 0.8510 - val_accuracy: 0.7064\n",
            "Epoch 925/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3851 - accuracy: 0.7724 - val_loss: 0.8397 - val_accuracy: 0.6986\n",
            "Epoch 926/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3993 - accuracy: 0.7685 - val_loss: 0.8321 - val_accuracy: 0.7021\n",
            "Epoch 927/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3820 - accuracy: 0.7744 - val_loss: 0.8384 - val_accuracy: 0.7021\n",
            "Epoch 928/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3994 - accuracy: 0.7668 - val_loss: 0.8367 - val_accuracy: 0.7030\n",
            "Epoch 929/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3882 - accuracy: 0.7755 - val_loss: 0.8470 - val_accuracy: 0.7056\n",
            "Epoch 930/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3848 - accuracy: 0.7798 - val_loss: 0.8418 - val_accuracy: 0.7064\n",
            "Epoch 931/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4056 - accuracy: 0.7657 - val_loss: 0.8198 - val_accuracy: 0.7030\n",
            "Epoch 932/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3890 - accuracy: 0.7652 - val_loss: 0.8169 - val_accuracy: 0.7038\n",
            "Epoch 933/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.7750 - val_loss: 0.8303 - val_accuracy: 0.7091\n",
            "Epoch 934/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3815 - accuracy: 0.7716 - val_loss: 0.8396 - val_accuracy: 0.7099\n",
            "Epoch 935/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3955 - accuracy: 0.7652 - val_loss: 0.8283 - val_accuracy: 0.7038\n",
            "Epoch 936/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3927 - accuracy: 0.7600 - val_loss: 0.8180 - val_accuracy: 0.6908\n",
            "Epoch 937/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3893 - accuracy: 0.7594 - val_loss: 0.8224 - val_accuracy: 0.6960\n",
            "Epoch 938/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3937 - accuracy: 0.7578 - val_loss: 0.8311 - val_accuracy: 0.7030\n",
            "Epoch 939/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3886 - accuracy: 0.7602 - val_loss: 0.8294 - val_accuracy: 0.6899\n",
            "Epoch 940/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3957 - accuracy: 0.7528 - val_loss: 0.8179 - val_accuracy: 0.6855\n",
            "Epoch 941/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.7602 - val_loss: 0.8213 - val_accuracy: 0.6986\n",
            "Epoch 942/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3833 - accuracy: 0.7668 - val_loss: 0.8305 - val_accuracy: 0.6995\n",
            "Epoch 943/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3901 - accuracy: 0.7657 - val_loss: 0.8467 - val_accuracy: 0.7003\n",
            "Epoch 944/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3864 - accuracy: 0.7692 - val_loss: 0.8283 - val_accuracy: 0.6882\n",
            "Epoch 945/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3963 - accuracy: 0.7561 - val_loss: 0.8195 - val_accuracy: 0.6899\n",
            "Epoch 946/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.4004 - accuracy: 0.7670 - val_loss: 0.8287 - val_accuracy: 0.6890\n",
            "Epoch 947/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3922 - accuracy: 0.7620 - val_loss: 0.8306 - val_accuracy: 0.6899\n",
            "Epoch 948/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4023 - accuracy: 0.7613 - val_loss: 0.8226 - val_accuracy: 0.6855\n",
            "Epoch 949/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3944 - accuracy: 0.7528 - val_loss: 0.8352 - val_accuracy: 0.6873\n",
            "Epoch 950/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3904 - accuracy: 0.7703 - val_loss: 0.8388 - val_accuracy: 0.6873\n",
            "Epoch 951/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3948 - accuracy: 0.7609 - val_loss: 0.8497 - val_accuracy: 0.6986\n",
            "Epoch 952/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3845 - accuracy: 0.7692 - val_loss: 0.8430 - val_accuracy: 0.6995\n",
            "Epoch 953/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3777 - accuracy: 0.7822 - val_loss: 0.8400 - val_accuracy: 0.6916\n",
            "Epoch 954/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3909 - accuracy: 0.7679 - val_loss: 0.8382 - val_accuracy: 0.6951\n",
            "Epoch 955/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3819 - accuracy: 0.7644 - val_loss: 0.8378 - val_accuracy: 0.6934\n",
            "Epoch 956/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3902 - accuracy: 0.7674 - val_loss: 0.8381 - val_accuracy: 0.6995\n",
            "Epoch 957/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3782 - accuracy: 0.7718 - val_loss: 0.8419 - val_accuracy: 0.6986\n",
            "Epoch 958/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3770 - accuracy: 0.7700 - val_loss: 0.8603 - val_accuracy: 0.7073\n",
            "Epoch 959/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3835 - accuracy: 0.7687 - val_loss: 0.8561 - val_accuracy: 0.7038\n",
            "Epoch 960/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3871 - accuracy: 0.7626 - val_loss: 0.8333 - val_accuracy: 0.6847\n",
            "Epoch 961/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3759 - accuracy: 0.7672 - val_loss: 0.8519 - val_accuracy: 0.6943\n",
            "Epoch 962/1000\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.3820 - accuracy: 0.7676 - val_loss: 0.8625 - val_accuracy: 0.7030\n",
            "Epoch 963/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3855 - accuracy: 0.7683 - val_loss: 0.8426 - val_accuracy: 0.6943\n",
            "Epoch 964/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3969 - accuracy: 0.7515 - val_loss: 0.8373 - val_accuracy: 0.6960\n",
            "Epoch 965/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3840 - accuracy: 0.7698 - val_loss: 0.8490 - val_accuracy: 0.7117\n",
            "Epoch 966/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3877 - accuracy: 0.7668 - val_loss: 0.8467 - val_accuracy: 0.7082\n",
            "Epoch 967/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3879 - accuracy: 0.7655 - val_loss: 0.8588 - val_accuracy: 0.7082\n",
            "Epoch 968/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3855 - accuracy: 0.7696 - val_loss: 0.8537 - val_accuracy: 0.6969\n",
            "Epoch 969/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3833 - accuracy: 0.7731 - val_loss: 0.8493 - val_accuracy: 0.6995\n",
            "Epoch 970/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3973 - accuracy: 0.7661 - val_loss: 0.8508 - val_accuracy: 0.6925\n",
            "Epoch 971/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3927 - accuracy: 0.7546 - val_loss: 0.8491 - val_accuracy: 0.6934\n",
            "Epoch 972/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.4119 - accuracy: 0.7570 - val_loss: 0.8385 - val_accuracy: 0.6969\n",
            "Epoch 973/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3872 - accuracy: 0.7711 - val_loss: 0.8528 - val_accuracy: 0.6951\n",
            "Epoch 974/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3943 - accuracy: 0.7650 - val_loss: 0.8451 - val_accuracy: 0.6960\n",
            "Epoch 975/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3908 - accuracy: 0.7633 - val_loss: 0.8427 - val_accuracy: 0.6995\n",
            "Epoch 976/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3853 - accuracy: 0.7768 - val_loss: 0.8575 - val_accuracy: 0.7030\n",
            "Epoch 977/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3785 - accuracy: 0.7764 - val_loss: 0.8651 - val_accuracy: 0.7082\n",
            "Epoch 978/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3816 - accuracy: 0.7755 - val_loss: 0.8598 - val_accuracy: 0.7064\n",
            "Epoch 979/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3863 - accuracy: 0.7733 - val_loss: 0.8637 - val_accuracy: 0.7003\n",
            "Epoch 980/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3890 - accuracy: 0.7596 - val_loss: 0.8485 - val_accuracy: 0.6951\n",
            "Epoch 981/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3827 - accuracy: 0.7700 - val_loss: 0.8504 - val_accuracy: 0.6960\n",
            "Epoch 982/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3792 - accuracy: 0.7707 - val_loss: 0.8580 - val_accuracy: 0.6995\n",
            "Epoch 983/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3823 - accuracy: 0.7670 - val_loss: 0.8619 - val_accuracy: 0.7003\n",
            "Epoch 984/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3935 - accuracy: 0.7696 - val_loss: 0.8582 - val_accuracy: 0.6977\n",
            "Epoch 985/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3973 - accuracy: 0.7644 - val_loss: 0.8449 - val_accuracy: 0.6986\n",
            "Epoch 986/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3813 - accuracy: 0.7674 - val_loss: 0.8451 - val_accuracy: 0.6934\n",
            "Epoch 987/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3932 - accuracy: 0.7642 - val_loss: 0.8554 - val_accuracy: 0.6969\n",
            "Epoch 988/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3822 - accuracy: 0.7700 - val_loss: 0.8550 - val_accuracy: 0.7003\n",
            "Epoch 989/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3884 - accuracy: 0.7648 - val_loss: 0.8602 - val_accuracy: 0.6951\n",
            "Epoch 990/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3849 - accuracy: 0.7676 - val_loss: 0.8572 - val_accuracy: 0.6960\n",
            "Epoch 991/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3838 - accuracy: 0.7713 - val_loss: 0.8805 - val_accuracy: 0.6960\n",
            "Epoch 992/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3872 - accuracy: 0.7737 - val_loss: 0.8923 - val_accuracy: 0.7003\n",
            "Epoch 993/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3821 - accuracy: 0.7700 - val_loss: 0.8804 - val_accuracy: 0.6951\n",
            "Epoch 994/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3845 - accuracy: 0.7611 - val_loss: 0.8862 - val_accuracy: 0.6969\n",
            "Epoch 995/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4035 - accuracy: 0.7644 - val_loss: 0.8814 - val_accuracy: 0.7003\n",
            "Epoch 996/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.7724 - val_loss: 0.8411 - val_accuracy: 0.7030\n",
            "Epoch 997/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3859 - accuracy: 0.7659 - val_loss: 0.8488 - val_accuracy: 0.7082\n",
            "Epoch 998/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.7648 - val_loss: 0.8514 - val_accuracy: 0.7082\n",
            "Epoch 999/1000\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.3850 - accuracy: 0.7713 - val_loss: 0.8576 - val_accuracy: 0.7021\n",
            "Epoch 1000/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3768 - accuracy: 0.7744 - val_loss: 0.8672 - val_accuracy: 0.7021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdef8c7f3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MzwZ4mW7yJO"
      },
      "source": [
        "y_pred = model.predict(X_val)\n",
        "y_pred = (y_pred > 0.5).astype('int64')\n",
        "y_pred = y_pred.reshape(len(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwDLlYK571f4"
      },
      "source": [
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu0Wzr00nQgg"
      },
      "source": [
        "## Loading Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cNU0D2enrg9"
      },
      "source": [
        "test_directories = []\n",
        "for i in glob(\"data/test/*/\"):\n",
        "    for j in glob(i+'*/'):\n",
        "        test_directories.append(j)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIG5cArRoXpa"
      },
      "source": [
        "test_data = []\n",
        "for i in test_directories:\n",
        "    with open(i+'data.json', encoding='utf-8') as f:\n",
        "        data.append(json.load(f))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvQqDonCoZCy"
      },
      "source": [
        "test_tweetid_data = []\n",
        "#for test\n",
        "for i in range(len(labels), len(data)):\n",
        "    for j in te_flatten(data[i]):\n",
        "        test_tweetid_data.append(j)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bmaq4d7oauA"
      },
      "source": [
        "test_df = pd.DataFrame(test_tweetid_data, columns = test_tweetid_data[0].keys(), index = None)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Q9h4KIFBocqk",
        "outputId": "bffeb055-2fb1-4555-99ed-c373ea13c95a"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1396844054818680835</td>\n",
              "      <td>Bhadva Ramdev was brought to a debate about Al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1396844158283776004</td>\n",
              "      <td>Bhadva Ramdev was brought to a debate about Al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1397043581446098945</td>\n",
              "      <td>Bhadva Ramdev was brought to a debate about Al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1398265913749635073</td>\n",
              "      <td>Bhadva Ramdev was brought to a debate about Al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1396852220268716032</td>\n",
              "      <td>Bhadva Ramdev was brought to a debate about Al...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id                                               text\n",
              "0  1396844054818680835  Bhadva Ramdev was brought to a debate about Al...\n",
              "1  1396844158283776004  Bhadva Ramdev was brought to a debate about Al...\n",
              "2  1397043581446098945  Bhadva Ramdev was brought to a debate about Al...\n",
              "3  1398265913749635073  Bhadva Ramdev was brought to a debate about Al...\n",
              "4  1396852220268716032  Bhadva Ramdev was brought to a debate about Al..."
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydXgZWvrpDq8"
      },
      "source": [
        "## Preprocessing Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIz2o7tCofam"
      },
      "source": [
        "test_tweets = test_df.text\n",
        "tweet_ids = test_df.tweet_id"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGSFh9AEojRu"
      },
      "source": [
        "cleaned_test = [clean_tweet(tweet) for tweet in test_tweets]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FVOSed1okxY"
      },
      "source": [
        "X_test = vectorizer.transform(cleaned_test)\n",
        "X_test = X_test.todense()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaIdVdlINmfC"
      },
      "source": [
        "## Making Prediction from Test Data - Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQbxw8JwNtKr"
      },
      "source": [
        "lr_pred = lr.predict(X_test)\n",
        "svc_pred = svc.predict(X_test)\n",
        "nb_pred = nb.predict(X_test)\n",
        "sgd_pred = sgd.predict(X_test)\n",
        "knn_pred = knn.predict(X_test)\n",
        "dt_pred = dt.predict(X_test)\n",
        "rf_pred = rf.predict(X_test)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C14il7sZN86m"
      },
      "source": [
        "# Voting\n",
        "\n",
        "submission_prediction = []\n",
        "\n",
        "for i in range(len(lr_pred)):\n",
        "    one = 0\n",
        "    zero = 0\n",
        "    predictions = [lr_pred[i], svc_pred[i], nb_pred[i], sgd_pred[i], knn_pred[i], dt_pred[i], rf_pred[i]]\n",
        "    # predictions = [lr_pred[i], nb_pred[i], sgd_pred[i], dt_pred[i], rf_pred[i]]\n",
        "    for pred in predictions:\n",
        "        if pred == 'HOF': one += 1\n",
        "        if pred == 'NONE': zero +=1\n",
        "    if one > zero: submission_prediction.append('HOF')\n",
        "    else: submission_prediction.append('NONE')\n",
        "\n",
        "submission_prediction = np.array(submission_prediction)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYaQ3VQVpH71"
      },
      "source": [
        "## Making Prediction from Test Data - Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC7QUhqFonE-"
      },
      "source": [
        "submission_prediction = model.predict(X_test)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkDB2rwsI6ON"
      },
      "source": [
        "submission_prediction = (submission_prediction > 0.5).astype('int64')\n",
        "submission_prediction = submission_prediction.reshape(len(submission_prediction))"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm_93A0yJITu"
      },
      "source": [
        "submission_prediction = submission_prediction.tolist()\n",
        "\n",
        "for i in range(len(submission_prediction)):\n",
        "    if submission_prediction[i] == 1:\n",
        "        submission_prediction[i] = 'HOF'\n",
        "    else:\n",
        "        submission_prediction[i] = 'NONE'\n",
        "\n",
        "submission_prediction = np.array(submission_prediction)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yczQzxsWpNM8"
      },
      "source": [
        "## Submitting Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vaTx1FPpMsx"
      },
      "source": [
        "submission = {'tweet_id': tweet_ids, 'label':submission_prediction}\n",
        "submission = pd.DataFrame(submission)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay_MnHaFopro"
      },
      "source": [
        "submission.to_csv('data/ensemble_submission.csv', index = False)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfRumU9bKgxD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}