{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IndicBertNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LPyKFQOvq3b"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44VfJizbIQrm",
        "outputId": "17178556-82f3-43f3-977f-6c2c2b4aeabe"
      },
      "source": [
        "% cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0vyNOIqv1EI"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rBs4FlCJQ0K"
      },
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIzn2KeiuyeB",
        "outputId": "07661ddc-bfe5-432d-ee8a-f478322479a2"
      },
      "source": [
        "output = []\n",
        "\n",
        "for i in range(29):\n",
        "    file_name = \"./embed_feat/output\" + str(i + 1) + \".txt\"\n",
        "    with open(file_name, \"rb\") as fp:   #Pickling\n",
        "        file_output = pickle.load(fp)\n",
        "        for x in file_output:\n",
        "            output.append(x)\n",
        "    print(file_name + \" done\")\n",
        "\n",
        "X = output\n",
        "output = []\n",
        "\n",
        "file_name = []\n",
        "file_output = []\n",
        "x = []\n",
        "\n",
        "print(len(X))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./embed_feat/output1.txt done\n",
            "./embed_feat/output2.txt done\n",
            "./embed_feat/output3.txt done\n",
            "./embed_feat/output4.txt done\n",
            "./embed_feat/output5.txt done\n",
            "./embed_feat/output6.txt done\n",
            "./embed_feat/output7.txt done\n",
            "./embed_feat/output8.txt done\n",
            "./embed_feat/output9.txt done\n",
            "./embed_feat/output10.txt done\n",
            "./embed_feat/output11.txt done\n",
            "./embed_feat/output12.txt done\n",
            "./embed_feat/output13.txt done\n",
            "./embed_feat/output14.txt done\n",
            "./embed_feat/output15.txt done\n",
            "./embed_feat/output16.txt done\n",
            "./embed_feat/output17.txt done\n",
            "./embed_feat/output18.txt done\n",
            "./embed_feat/output19.txt done\n",
            "./embed_feat/output20.txt done\n",
            "./embed_feat/output21.txt done\n",
            "./embed_feat/output22.txt done\n",
            "./embed_feat/output23.txt done\n",
            "./embed_feat/output24.txt done\n",
            "./embed_feat/output25.txt done\n",
            "./embed_feat/output26.txt done\n",
            "./embed_feat/output27.txt done\n",
            "./embed_feat/output28.txt done\n",
            "./embed_feat/output29.txt done\n",
            "5740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT3KBz5Du1XQ",
        "outputId": "44832879-3902-449a-e0e4-a3f195d9a5aa"
      },
      "source": [
        "with open('./embed_labels/label.txt', \"rb\") as fp:\n",
        "        y = pickle.load(fp)\n",
        "\n",
        "print(len(y))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7ImRfI5vKMR"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X = []\n",
        "y = []"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV8LsYCCGlmI"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "X_train = X_train.reshape(4592, 158208)\n",
        "\n",
        "X_val = np.array(X_val)\n",
        "X_val = X_val.reshape(1148, 158208)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EU6W2TiznVG"
      },
      "source": [
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "X_val = StandardScaler().fit_transform(X_val)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPxU1iZe2JzD"
      },
      "source": [
        "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(MyThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        val_acc = logs[\"val_accuracy\"]\n",
        "        if val_acc >= self.threshold:\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ouwzoDJAOsi"
      },
      "source": [
        "'''\n",
        "model = models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(32, input_dim=158208, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "''' \n",
        "\n",
        "callback = MyThresholdCallback(threshold=0.70)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(32, input_dim=158208, kernel_initializer='normal', activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.6))\n",
        "model.add(tf.keras.layers.Dense(16, kernel_initializer='normal', activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Dense(8, kernel_initializer='normal', activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizer_fn = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
        "\n",
        "model.compile(optimizer=optimizer_fn,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UBpErxjKh8B",
        "outputId": "d441e642-9cdc-4021-e01c-ff0b2f024fe8"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs = 1000, batch_size = 32, validation_data=(X_val, y_val), callbacks=[callback])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "144/144 [==============================] - 6s 21ms/step - loss: 0.6956 - accuracy: 0.4956 - val_loss: 0.6934 - val_accuracy: 0.4878\n",
            "Epoch 2/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6936 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.4930\n",
            "Epoch 3/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6930 - accuracy: 0.5030 - val_loss: 0.6930 - val_accuracy: 0.4948\n",
            "Epoch 4/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6932 - accuracy: 0.5094 - val_loss: 0.6928 - val_accuracy: 0.4878\n",
            "Epoch 5/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.4913\n",
            "Epoch 6/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6927 - accuracy: 0.5122 - val_loss: 0.6922 - val_accuracy: 0.4913\n",
            "Epoch 7/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6920 - accuracy: 0.5174 - val_loss: 0.6918 - val_accuracy: 0.4922\n",
            "Epoch 8/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6922 - accuracy: 0.5316 - val_loss: 0.6914 - val_accuracy: 0.4913\n",
            "Epoch 9/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6912 - accuracy: 0.5270 - val_loss: 0.6906 - val_accuracy: 0.5070\n",
            "Epoch 10/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6910 - accuracy: 0.5246 - val_loss: 0.6899 - val_accuracy: 0.5209\n",
            "Epoch 11/1000\n",
            "144/144 [==============================] - 3s 19ms/step - loss: 0.6892 - accuracy: 0.5379 - val_loss: 0.6886 - val_accuracy: 0.5375\n",
            "Epoch 12/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6884 - accuracy: 0.5333 - val_loss: 0.6868 - val_accuracy: 0.5470\n",
            "Epoch 13/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6884 - accuracy: 0.5403 - val_loss: 0.6853 - val_accuracy: 0.5618\n",
            "Epoch 14/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6832 - accuracy: 0.5625 - val_loss: 0.6825 - val_accuracy: 0.5706\n",
            "Epoch 15/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6849 - accuracy: 0.5459 - val_loss: 0.6800 - val_accuracy: 0.5836\n",
            "Epoch 16/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6832 - accuracy: 0.5429 - val_loss: 0.6775 - val_accuracy: 0.5889\n",
            "Epoch 17/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6768 - accuracy: 0.5703 - val_loss: 0.6732 - val_accuracy: 0.6037\n",
            "Epoch 18/1000\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.6767 - accuracy: 0.5723 - val_loss: 0.6700 - val_accuracy: 0.6063\n",
            "Epoch 19/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6743 - accuracy: 0.5688 - val_loss: 0.6668 - val_accuracy: 0.6185\n",
            "Epoch 20/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6722 - accuracy: 0.5791 - val_loss: 0.6637 - val_accuracy: 0.6202\n",
            "Epoch 21/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6674 - accuracy: 0.5936 - val_loss: 0.6593 - val_accuracy: 0.6350\n",
            "Epoch 22/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6659 - accuracy: 0.5930 - val_loss: 0.6558 - val_accuracy: 0.6324\n",
            "Epoch 23/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6570 - accuracy: 0.6010 - val_loss: 0.6518 - val_accuracy: 0.6411\n",
            "Epoch 24/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6581 - accuracy: 0.5976 - val_loss: 0.6487 - val_accuracy: 0.6376\n",
            "Epoch 25/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6608 - accuracy: 0.5928 - val_loss: 0.6490 - val_accuracy: 0.6429\n",
            "Epoch 26/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6610 - accuracy: 0.6028 - val_loss: 0.6481 - val_accuracy: 0.6368\n",
            "Epoch 27/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6497 - accuracy: 0.6087 - val_loss: 0.6439 - val_accuracy: 0.6350\n",
            "Epoch 28/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6507 - accuracy: 0.6167 - val_loss: 0.6426 - val_accuracy: 0.6455\n",
            "Epoch 29/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6517 - accuracy: 0.6165 - val_loss: 0.6412 - val_accuracy: 0.6463\n",
            "Epoch 30/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6446 - accuracy: 0.6226 - val_loss: 0.6395 - val_accuracy: 0.6437\n",
            "Epoch 31/1000\n",
            "144/144 [==============================] - 3s 17ms/step - loss: 0.6423 - accuracy: 0.6241 - val_loss: 0.6374 - val_accuracy: 0.6455\n",
            "Epoch 32/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6469 - accuracy: 0.6241 - val_loss: 0.6388 - val_accuracy: 0.6385\n",
            "Epoch 33/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6419 - accuracy: 0.6311 - val_loss: 0.6358 - val_accuracy: 0.6498\n",
            "Epoch 34/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6332 - accuracy: 0.6339 - val_loss: 0.6334 - val_accuracy: 0.6463\n",
            "Epoch 35/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6372 - accuracy: 0.6341 - val_loss: 0.6333 - val_accuracy: 0.6516\n",
            "Epoch 36/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6355 - accuracy: 0.6383 - val_loss: 0.6324 - val_accuracy: 0.6516\n",
            "Epoch 37/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6339 - accuracy: 0.6374 - val_loss: 0.6311 - val_accuracy: 0.6542\n",
            "Epoch 38/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6354 - accuracy: 0.6365 - val_loss: 0.6303 - val_accuracy: 0.6638\n",
            "Epoch 39/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6278 - accuracy: 0.6426 - val_loss: 0.6290 - val_accuracy: 0.6551\n",
            "Epoch 40/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6258 - accuracy: 0.6459 - val_loss: 0.6278 - val_accuracy: 0.6577\n",
            "Epoch 41/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6279 - accuracy: 0.6394 - val_loss: 0.6278 - val_accuracy: 0.6611\n",
            "Epoch 42/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6215 - accuracy: 0.6435 - val_loss: 0.6271 - val_accuracy: 0.6611\n",
            "Epoch 43/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6181 - accuracy: 0.6598 - val_loss: 0.6235 - val_accuracy: 0.6594\n",
            "Epoch 44/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6272 - accuracy: 0.6485 - val_loss: 0.6253 - val_accuracy: 0.6585\n",
            "Epoch 45/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6238 - accuracy: 0.6553 - val_loss: 0.6239 - val_accuracy: 0.6611\n",
            "Epoch 46/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6118 - accuracy: 0.6649 - val_loss: 0.6213 - val_accuracy: 0.6664\n",
            "Epoch 47/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6205 - accuracy: 0.6614 - val_loss: 0.6222 - val_accuracy: 0.6611\n",
            "Epoch 48/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6110 - accuracy: 0.6583 - val_loss: 0.6210 - val_accuracy: 0.6620\n",
            "Epoch 49/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6167 - accuracy: 0.6496 - val_loss: 0.6237 - val_accuracy: 0.6594\n",
            "Epoch 50/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6128 - accuracy: 0.6611 - val_loss: 0.6202 - val_accuracy: 0.6603\n",
            "Epoch 51/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6091 - accuracy: 0.6644 - val_loss: 0.6204 - val_accuracy: 0.6611\n",
            "Epoch 52/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6041 - accuracy: 0.6742 - val_loss: 0.6185 - val_accuracy: 0.6603\n",
            "Epoch 53/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6012 - accuracy: 0.6788 - val_loss: 0.6172 - val_accuracy: 0.6646\n",
            "Epoch 54/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6079 - accuracy: 0.6725 - val_loss: 0.6170 - val_accuracy: 0.6611\n",
            "Epoch 55/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6075 - accuracy: 0.6675 - val_loss: 0.6166 - val_accuracy: 0.6629\n",
            "Epoch 56/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6032 - accuracy: 0.6712 - val_loss: 0.6169 - val_accuracy: 0.6646\n",
            "Epoch 57/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6014 - accuracy: 0.6707 - val_loss: 0.6180 - val_accuracy: 0.6594\n",
            "Epoch 58/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5976 - accuracy: 0.6688 - val_loss: 0.6159 - val_accuracy: 0.6629\n",
            "Epoch 59/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5971 - accuracy: 0.6773 - val_loss: 0.6153 - val_accuracy: 0.6629\n",
            "Epoch 60/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.6006 - accuracy: 0.6818 - val_loss: 0.6140 - val_accuracy: 0.6681\n",
            "Epoch 61/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5973 - accuracy: 0.6786 - val_loss: 0.6148 - val_accuracy: 0.6620\n",
            "Epoch 62/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5933 - accuracy: 0.6799 - val_loss: 0.6134 - val_accuracy: 0.6620\n",
            "Epoch 63/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5936 - accuracy: 0.6766 - val_loss: 0.6126 - val_accuracy: 0.6629\n",
            "Epoch 64/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5907 - accuracy: 0.6851 - val_loss: 0.6113 - val_accuracy: 0.6629\n",
            "Epoch 65/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5915 - accuracy: 0.6860 - val_loss: 0.6123 - val_accuracy: 0.6629\n",
            "Epoch 66/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5864 - accuracy: 0.6855 - val_loss: 0.6112 - val_accuracy: 0.6638\n",
            "Epoch 67/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5929 - accuracy: 0.6882 - val_loss: 0.6125 - val_accuracy: 0.6655\n",
            "Epoch 68/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5896 - accuracy: 0.6964 - val_loss: 0.6121 - val_accuracy: 0.6655\n",
            "Epoch 69/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5831 - accuracy: 0.6932 - val_loss: 0.6110 - val_accuracy: 0.6638\n",
            "Epoch 70/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5835 - accuracy: 0.6921 - val_loss: 0.6113 - val_accuracy: 0.6603\n",
            "Epoch 71/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5814 - accuracy: 0.6879 - val_loss: 0.6114 - val_accuracy: 0.6611\n",
            "Epoch 72/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5739 - accuracy: 0.7001 - val_loss: 0.6102 - val_accuracy: 0.6646\n",
            "Epoch 73/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5771 - accuracy: 0.6940 - val_loss: 0.6108 - val_accuracy: 0.6533\n",
            "Epoch 74/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5790 - accuracy: 0.6975 - val_loss: 0.6109 - val_accuracy: 0.6577\n",
            "Epoch 75/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5765 - accuracy: 0.6980 - val_loss: 0.6099 - val_accuracy: 0.6559\n",
            "Epoch 76/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5806 - accuracy: 0.6964 - val_loss: 0.6093 - val_accuracy: 0.6620\n",
            "Epoch 77/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5766 - accuracy: 0.7023 - val_loss: 0.6097 - val_accuracy: 0.6585\n",
            "Epoch 78/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5745 - accuracy: 0.7067 - val_loss: 0.6077 - val_accuracy: 0.6646\n",
            "Epoch 79/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5681 - accuracy: 0.7145 - val_loss: 0.6076 - val_accuracy: 0.6620\n",
            "Epoch 80/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5647 - accuracy: 0.7091 - val_loss: 0.6069 - val_accuracy: 0.6611\n",
            "Epoch 81/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5725 - accuracy: 0.7038 - val_loss: 0.6073 - val_accuracy: 0.6611\n",
            "Epoch 82/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5722 - accuracy: 0.7041 - val_loss: 0.6073 - val_accuracy: 0.6629\n",
            "Epoch 83/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5697 - accuracy: 0.7091 - val_loss: 0.6071 - val_accuracy: 0.6577\n",
            "Epoch 84/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5628 - accuracy: 0.7154 - val_loss: 0.6065 - val_accuracy: 0.6603\n",
            "Epoch 85/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5633 - accuracy: 0.7106 - val_loss: 0.6072 - val_accuracy: 0.6611\n",
            "Epoch 86/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5588 - accuracy: 0.7064 - val_loss: 0.6067 - val_accuracy: 0.6629\n",
            "Epoch 87/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5603 - accuracy: 0.7143 - val_loss: 0.6055 - val_accuracy: 0.6638\n",
            "Epoch 88/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5552 - accuracy: 0.7169 - val_loss: 0.6059 - val_accuracy: 0.6646\n",
            "Epoch 89/1000\n",
            "144/144 [==============================] - 3s 17ms/step - loss: 0.5528 - accuracy: 0.7189 - val_loss: 0.6043 - val_accuracy: 0.6699\n",
            "Epoch 90/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5594 - accuracy: 0.7195 - val_loss: 0.6049 - val_accuracy: 0.6699\n",
            "Epoch 91/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5568 - accuracy: 0.7206 - val_loss: 0.6049 - val_accuracy: 0.6638\n",
            "Epoch 92/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5434 - accuracy: 0.7295 - val_loss: 0.6043 - val_accuracy: 0.6638\n",
            "Epoch 93/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5470 - accuracy: 0.7300 - val_loss: 0.6033 - val_accuracy: 0.6716\n",
            "Epoch 94/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5485 - accuracy: 0.7195 - val_loss: 0.6033 - val_accuracy: 0.6690\n",
            "Epoch 95/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5455 - accuracy: 0.7326 - val_loss: 0.6041 - val_accuracy: 0.6690\n",
            "Epoch 96/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5295 - accuracy: 0.7374 - val_loss: 0.6046 - val_accuracy: 0.6690\n",
            "Epoch 97/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5367 - accuracy: 0.7260 - val_loss: 0.6051 - val_accuracy: 0.6646\n",
            "Epoch 98/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5425 - accuracy: 0.7278 - val_loss: 0.6056 - val_accuracy: 0.6681\n",
            "Epoch 99/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5470 - accuracy: 0.7274 - val_loss: 0.6034 - val_accuracy: 0.6681\n",
            "Epoch 100/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5401 - accuracy: 0.7232 - val_loss: 0.6033 - val_accuracy: 0.6655\n",
            "Epoch 101/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5348 - accuracy: 0.7361 - val_loss: 0.6031 - val_accuracy: 0.6707\n",
            "Epoch 102/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5313 - accuracy: 0.7319 - val_loss: 0.6027 - val_accuracy: 0.6672\n",
            "Epoch 103/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5370 - accuracy: 0.7334 - val_loss: 0.6019 - val_accuracy: 0.6733\n",
            "Epoch 104/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5316 - accuracy: 0.7361 - val_loss: 0.6021 - val_accuracy: 0.6690\n",
            "Epoch 105/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5213 - accuracy: 0.7369 - val_loss: 0.6018 - val_accuracy: 0.6742\n",
            "Epoch 106/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5334 - accuracy: 0.7361 - val_loss: 0.6012 - val_accuracy: 0.6751\n",
            "Epoch 107/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5270 - accuracy: 0.7415 - val_loss: 0.6014 - val_accuracy: 0.6725\n",
            "Epoch 108/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5234 - accuracy: 0.7415 - val_loss: 0.6013 - val_accuracy: 0.6716\n",
            "Epoch 109/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5256 - accuracy: 0.7439 - val_loss: 0.6016 - val_accuracy: 0.6733\n",
            "Epoch 110/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5260 - accuracy: 0.7437 - val_loss: 0.6018 - val_accuracy: 0.6707\n",
            "Epoch 111/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5180 - accuracy: 0.7474 - val_loss: 0.6008 - val_accuracy: 0.6725\n",
            "Epoch 112/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5214 - accuracy: 0.7432 - val_loss: 0.6020 - val_accuracy: 0.6716\n",
            "Epoch 113/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5170 - accuracy: 0.7430 - val_loss: 0.6016 - val_accuracy: 0.6725\n",
            "Epoch 114/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5169 - accuracy: 0.7432 - val_loss: 0.6004 - val_accuracy: 0.6751\n",
            "Epoch 115/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5169 - accuracy: 0.7424 - val_loss: 0.6001 - val_accuracy: 0.6786\n",
            "Epoch 116/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5021 - accuracy: 0.7635 - val_loss: 0.6012 - val_accuracy: 0.6794\n",
            "Epoch 117/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5134 - accuracy: 0.7520 - val_loss: 0.5998 - val_accuracy: 0.6794\n",
            "Epoch 118/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4981 - accuracy: 0.7605 - val_loss: 0.6016 - val_accuracy: 0.6707\n",
            "Epoch 119/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5101 - accuracy: 0.7574 - val_loss: 0.6011 - val_accuracy: 0.6681\n",
            "Epoch 120/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5066 - accuracy: 0.7552 - val_loss: 0.6002 - val_accuracy: 0.6777\n",
            "Epoch 121/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5038 - accuracy: 0.7576 - val_loss: 0.6007 - val_accuracy: 0.6733\n",
            "Epoch 122/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5070 - accuracy: 0.7557 - val_loss: 0.5992 - val_accuracy: 0.6768\n",
            "Epoch 123/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4996 - accuracy: 0.7591 - val_loss: 0.5990 - val_accuracy: 0.6803\n",
            "Epoch 124/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5061 - accuracy: 0.7563 - val_loss: 0.5990 - val_accuracy: 0.6742\n",
            "Epoch 125/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4958 - accuracy: 0.7574 - val_loss: 0.5993 - val_accuracy: 0.6768\n",
            "Epoch 126/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.5028 - accuracy: 0.7581 - val_loss: 0.5984 - val_accuracy: 0.6733\n",
            "Epoch 127/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4957 - accuracy: 0.7635 - val_loss: 0.5987 - val_accuracy: 0.6786\n",
            "Epoch 128/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4935 - accuracy: 0.7607 - val_loss: 0.5979 - val_accuracy: 0.6821\n",
            "Epoch 129/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4873 - accuracy: 0.7655 - val_loss: 0.5980 - val_accuracy: 0.6794\n",
            "Epoch 130/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4944 - accuracy: 0.7607 - val_loss: 0.5977 - val_accuracy: 0.6812\n",
            "Epoch 131/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4788 - accuracy: 0.7661 - val_loss: 0.5994 - val_accuracy: 0.6777\n",
            "Epoch 132/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4887 - accuracy: 0.7711 - val_loss: 0.5994 - val_accuracy: 0.6751\n",
            "Epoch 133/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4803 - accuracy: 0.7633 - val_loss: 0.5989 - val_accuracy: 0.6803\n",
            "Epoch 134/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4799 - accuracy: 0.7720 - val_loss: 0.5995 - val_accuracy: 0.6838\n",
            "Epoch 135/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4719 - accuracy: 0.7713 - val_loss: 0.6002 - val_accuracy: 0.6812\n",
            "Epoch 136/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4723 - accuracy: 0.7753 - val_loss: 0.5995 - val_accuracy: 0.6786\n",
            "Epoch 137/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4852 - accuracy: 0.7744 - val_loss: 0.5978 - val_accuracy: 0.6786\n",
            "Epoch 138/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4623 - accuracy: 0.7835 - val_loss: 0.6003 - val_accuracy: 0.6873\n",
            "Epoch 139/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4677 - accuracy: 0.7822 - val_loss: 0.5987 - val_accuracy: 0.6855\n",
            "Epoch 140/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4707 - accuracy: 0.7744 - val_loss: 0.6007 - val_accuracy: 0.6855\n",
            "Epoch 141/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4712 - accuracy: 0.7748 - val_loss: 0.6013 - val_accuracy: 0.6821\n",
            "Epoch 142/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4618 - accuracy: 0.7807 - val_loss: 0.6029 - val_accuracy: 0.6821\n",
            "Epoch 143/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4679 - accuracy: 0.7757 - val_loss: 0.6023 - val_accuracy: 0.6794\n",
            "Epoch 144/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4641 - accuracy: 0.7744 - val_loss: 0.6033 - val_accuracy: 0.6803\n",
            "Epoch 145/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4641 - accuracy: 0.7833 - val_loss: 0.6020 - val_accuracy: 0.6821\n",
            "Epoch 146/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4564 - accuracy: 0.7875 - val_loss: 0.6026 - val_accuracy: 0.6786\n",
            "Epoch 147/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4579 - accuracy: 0.7783 - val_loss: 0.5987 - val_accuracy: 0.6777\n",
            "Epoch 148/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4506 - accuracy: 0.7946 - val_loss: 0.6002 - val_accuracy: 0.6829\n",
            "Epoch 149/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4573 - accuracy: 0.7879 - val_loss: 0.6001 - val_accuracy: 0.6847\n",
            "Epoch 150/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4587 - accuracy: 0.7855 - val_loss: 0.5988 - val_accuracy: 0.6838\n",
            "Epoch 151/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4465 - accuracy: 0.7842 - val_loss: 0.6014 - val_accuracy: 0.6864\n",
            "Epoch 152/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4439 - accuracy: 0.7864 - val_loss: 0.6041 - val_accuracy: 0.6821\n",
            "Epoch 153/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4320 - accuracy: 0.7925 - val_loss: 0.6052 - val_accuracy: 0.6882\n",
            "Epoch 154/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4383 - accuracy: 0.7864 - val_loss: 0.6071 - val_accuracy: 0.6838\n",
            "Epoch 155/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4364 - accuracy: 0.7957 - val_loss: 0.6037 - val_accuracy: 0.6855\n",
            "Epoch 156/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4337 - accuracy: 0.7959 - val_loss: 0.6044 - val_accuracy: 0.6847\n",
            "Epoch 157/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4325 - accuracy: 0.7953 - val_loss: 0.6046 - val_accuracy: 0.6916\n",
            "Epoch 158/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4289 - accuracy: 0.7977 - val_loss: 0.6051 - val_accuracy: 0.6960\n",
            "Epoch 159/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4198 - accuracy: 0.8047 - val_loss: 0.6070 - val_accuracy: 0.6925\n",
            "Epoch 160/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4089 - accuracy: 0.8042 - val_loss: 0.6164 - val_accuracy: 0.6951\n",
            "Epoch 161/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4190 - accuracy: 0.8088 - val_loss: 0.6017 - val_accuracy: 0.6943\n",
            "Epoch 162/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4171 - accuracy: 0.8029 - val_loss: 0.6052 - val_accuracy: 0.6916\n",
            "Epoch 163/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4207 - accuracy: 0.7973 - val_loss: 0.6038 - val_accuracy: 0.6899\n",
            "Epoch 164/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4185 - accuracy: 0.7997 - val_loss: 0.6005 - val_accuracy: 0.6986\n",
            "Epoch 165/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4220 - accuracy: 0.8047 - val_loss: 0.6013 - val_accuracy: 0.6969\n",
            "Epoch 166/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4078 - accuracy: 0.8095 - val_loss: 0.6053 - val_accuracy: 0.6934\n",
            "Epoch 167/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4089 - accuracy: 0.8105 - val_loss: 0.6059 - val_accuracy: 0.6934\n",
            "Epoch 168/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4036 - accuracy: 0.8092 - val_loss: 0.6116 - val_accuracy: 0.6986\n",
            "Epoch 169/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4116 - accuracy: 0.8079 - val_loss: 0.6108 - val_accuracy: 0.6943\n",
            "Epoch 170/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4071 - accuracy: 0.8134 - val_loss: 0.6115 - val_accuracy: 0.6960\n",
            "Epoch 171/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.4017 - accuracy: 0.8212 - val_loss: 0.6129 - val_accuracy: 0.6873\n",
            "Epoch 172/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.3876 - accuracy: 0.8212 - val_loss: 0.6149 - val_accuracy: 0.6951\n",
            "Epoch 173/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.3995 - accuracy: 0.8195 - val_loss: 0.6166 - val_accuracy: 0.6995\n",
            "Epoch 174/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.3968 - accuracy: 0.8112 - val_loss: 0.6145 - val_accuracy: 0.6969\n",
            "Epoch 175/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.3974 - accuracy: 0.8127 - val_loss: 0.6096 - val_accuracy: 0.6969\n",
            "Epoch 176/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.3893 - accuracy: 0.8164 - val_loss: 0.6113 - val_accuracy: 0.6934\n",
            "Epoch 177/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.3773 - accuracy: 0.8288 - val_loss: 0.6254 - val_accuracy: 0.6934\n",
            "Epoch 178/1000\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.3881 - accuracy: 0.8182 - val_loss: 0.6150 - val_accuracy: 0.7003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeDJweXDKv3r"
      },
      "source": [
        "y_pred = model.predict(X_val)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZMvglrjLzy-"
      },
      "source": [
        "y_pred = (y_pred > 0.5).astype('int64')\n",
        "y_pred = y_pred.reshape(len(y_pred))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhImhVerLesm",
        "outputId": "bb7d414a-b538-438b-ccf1-269122fe74c5"
      },
      "source": [
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.70      0.70       571\n",
            "           1       0.70      0.70      0.70       577\n",
            "\n",
            "    accuracy                           0.70      1148\n",
            "   macro avg       0.70      0.70      0.70      1148\n",
            "weighted avg       0.70      0.70      0.70      1148\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "1dVls7bZBMKI",
        "outputId": "2177fe54-c9d8-474e-cd0d-efc677257236"
      },
      "source": [
        "figure= plt.figure(figsize=(10,4))\n",
        "ax = plt.subplot(121)\n",
        "ax.plot(history.history['loss'], 'r', label='train')\n",
        "ax.plot(history.history['val_loss'], 'g', label='val')\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(axis='y')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "ax2 = plt.subplot(122)\n",
        "ax2.plot(history.history['accuracy'], 'b', label=\"train\")\n",
        "ax2.plot(history.history['val_accuracy'], 'g', label=\"val\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.grid(axis='y')\n",
        "# plt.savefig(\"cifar10_training_val_no_dropout\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTHu-ZWGLhQ3"
      },
      "source": [
        "model = []\n",
        "y_pred = []"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwQuztQKszGl"
      },
      "source": [
        "## Train on complete Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ussB3m0FW3DC",
        "outputId": "8acd8bcb-ab9d-4f47-8837-b6477a6102d3"
      },
      "source": [
        "output = []\n",
        "\n",
        "for i in range(29):\n",
        "    file_name = \"./embed_feat/output\" + str(i + 1) + \".txt\"\n",
        "    with open(file_name, \"rb\") as fp:   #Pickling\n",
        "        file_output = pickle.load(fp)\n",
        "        for x in file_output:\n",
        "            output.append(x)\n",
        "    print(file_name + \" done\")\n",
        "\n",
        "X = output\n",
        "output = []\n",
        "\n",
        "file_name = []\n",
        "file_output = []\n",
        "x = []\n",
        "\n",
        "print(len(X))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./embed_feat/output1.txt done\n",
            "./embed_feat/output2.txt done\n",
            "./embed_feat/output3.txt done\n",
            "./embed_feat/output4.txt done\n",
            "./embed_feat/output5.txt done\n",
            "./embed_feat/output6.txt done\n",
            "./embed_feat/output7.txt done\n",
            "./embed_feat/output8.txt done\n",
            "./embed_feat/output9.txt done\n",
            "./embed_feat/output10.txt done\n",
            "./embed_feat/output11.txt done\n",
            "./embed_feat/output12.txt done\n",
            "./embed_feat/output13.txt done\n",
            "./embed_feat/output14.txt done\n",
            "./embed_feat/output15.txt done\n",
            "./embed_feat/output16.txt done\n",
            "./embed_feat/output17.txt done\n",
            "./embed_feat/output18.txt done\n",
            "./embed_feat/output19.txt done\n",
            "./embed_feat/output20.txt done\n",
            "./embed_feat/output21.txt done\n",
            "./embed_feat/output22.txt done\n",
            "./embed_feat/output23.txt done\n",
            "./embed_feat/output24.txt done\n",
            "./embed_feat/output25.txt done\n",
            "./embed_feat/output26.txt done\n",
            "./embed_feat/output27.txt done\n",
            "./embed_feat/output28.txt done\n",
            "./embed_feat/output29.txt done\n",
            "5740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yUNEROps8xZ",
        "outputId": "0bc3e16d-bd79-43fe-d949-e559e7820ebf"
      },
      "source": [
        "with open('./embed_labels/label.txt', \"rb\") as fp:\n",
        "        y = pickle.load(fp)\n",
        "\n",
        "print(len(y))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgEKkr1Hs9Y9"
      },
      "source": [
        "X = np.array(X)\n",
        "X = X.reshape(5740, 158208)\n",
        "y = np.array(y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9udMwwswqkN"
      },
      "source": [
        "X = StandardScaler().fit_transform(X)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvNqjQBYyoyo"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(32, input_dim=158208, kernel_initializer='normal', activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.6))\n",
        "model.add(tf.keras.layers.Dense(16, kernel_initializer='normal', activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Dense(8, kernel_initializer='normal', activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizer_fn = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
        "\n",
        "model.compile(optimizer=optimizer_fn,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fzZuGdpy0RN",
        "outputId": "4dec3483-60bd-406d-b6c6-e60d479821fd"
      },
      "source": [
        "history = model.fit(X, y, epochs = 200, batch_size = 32)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "180/180 [==============================] - 6s 15ms/step - loss: 0.6946 - accuracy: 0.4972\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6923 - accuracy: 0.5179\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6909 - accuracy: 0.5197\n",
            "Epoch 4/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6903 - accuracy: 0.5235\n",
            "Epoch 5/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6888 - accuracy: 0.5376\n",
            "Epoch 6/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6882 - accuracy: 0.5402\n",
            "Epoch 7/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6872 - accuracy: 0.5303\n",
            "Epoch 8/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6805 - accuracy: 0.5575\n",
            "Epoch 9/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6809 - accuracy: 0.5505\n",
            "Epoch 10/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6766 - accuracy: 0.5704\n",
            "Epoch 11/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6771 - accuracy: 0.5732\n",
            "Epoch 12/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6759 - accuracy: 0.5676\n",
            "Epoch 13/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6719 - accuracy: 0.5784\n",
            "Epoch 14/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6694 - accuracy: 0.5742\n",
            "Epoch 15/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6709 - accuracy: 0.5747\n",
            "Epoch 16/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6668 - accuracy: 0.5887\n",
            "Epoch 17/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6602 - accuracy: 0.5988\n",
            "Epoch 18/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6637 - accuracy: 0.5944\n",
            "Epoch 19/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6612 - accuracy: 0.5956\n",
            "Epoch 20/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6576 - accuracy: 0.6035\n",
            "Epoch 21/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6596 - accuracy: 0.5932\n",
            "Epoch 22/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6544 - accuracy: 0.6120\n",
            "Epoch 23/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6537 - accuracy: 0.6120\n",
            "Epoch 24/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6513 - accuracy: 0.6033\n",
            "Epoch 25/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6524 - accuracy: 0.6268\n",
            "Epoch 26/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6491 - accuracy: 0.6150\n",
            "Epoch 27/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6481 - accuracy: 0.6139\n",
            "Epoch 28/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6468 - accuracy: 0.6145\n",
            "Epoch 29/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6435 - accuracy: 0.6296\n",
            "Epoch 30/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6423 - accuracy: 0.6258\n",
            "Epoch 31/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6365 - accuracy: 0.6347\n",
            "Epoch 32/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6393 - accuracy: 0.6307\n",
            "Epoch 33/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6394 - accuracy: 0.6328\n",
            "Epoch 34/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6374 - accuracy: 0.6270\n",
            "Epoch 35/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6354 - accuracy: 0.6385\n",
            "Epoch 36/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6317 - accuracy: 0.6416\n",
            "Epoch 37/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6365 - accuracy: 0.6314\n",
            "Epoch 38/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6315 - accuracy: 0.6509\n",
            "Epoch 39/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6242 - accuracy: 0.6516\n",
            "Epoch 40/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6280 - accuracy: 0.6477\n",
            "Epoch 41/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6279 - accuracy: 0.6483\n",
            "Epoch 42/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6239 - accuracy: 0.6467\n",
            "Epoch 43/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6238 - accuracy: 0.6523\n",
            "Epoch 44/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6212 - accuracy: 0.6526\n",
            "Epoch 45/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6237 - accuracy: 0.6571\n",
            "Epoch 46/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6219 - accuracy: 0.6563\n",
            "Epoch 47/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6210 - accuracy: 0.6557\n",
            "Epoch 48/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6130 - accuracy: 0.6582\n",
            "Epoch 49/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6169 - accuracy: 0.6587\n",
            "Epoch 50/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6104 - accuracy: 0.6664\n",
            "Epoch 51/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6145 - accuracy: 0.6622\n",
            "Epoch 52/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6187 - accuracy: 0.6681\n",
            "Epoch 53/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6128 - accuracy: 0.6618\n",
            "Epoch 54/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6036 - accuracy: 0.6667\n",
            "Epoch 55/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6100 - accuracy: 0.6721\n",
            "Epoch 56/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6104 - accuracy: 0.6706\n",
            "Epoch 57/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6085 - accuracy: 0.6726\n",
            "Epoch 58/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6047 - accuracy: 0.6636\n",
            "Epoch 59/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6005 - accuracy: 0.6730\n",
            "Epoch 60/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6012 - accuracy: 0.6714\n",
            "Epoch 61/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6003 - accuracy: 0.6848\n",
            "Epoch 62/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.6021 - accuracy: 0.6735\n",
            "Epoch 63/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5982 - accuracy: 0.6847\n",
            "Epoch 64/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5980 - accuracy: 0.6784\n",
            "Epoch 65/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5961 - accuracy: 0.6805\n",
            "Epoch 66/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5975 - accuracy: 0.6834\n",
            "Epoch 67/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5890 - accuracy: 0.6894\n",
            "Epoch 68/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5900 - accuracy: 0.6871\n",
            "Epoch 69/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5895 - accuracy: 0.6958\n",
            "Epoch 70/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5867 - accuracy: 0.6936\n",
            "Epoch 71/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5865 - accuracy: 0.6885\n",
            "Epoch 72/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5860 - accuracy: 0.6969\n",
            "Epoch 73/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5813 - accuracy: 0.6977\n",
            "Epoch 74/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5852 - accuracy: 0.6885\n",
            "Epoch 75/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5799 - accuracy: 0.6997\n",
            "Epoch 76/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5847 - accuracy: 0.6920\n",
            "Epoch 77/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5740 - accuracy: 0.6995\n",
            "Epoch 78/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5789 - accuracy: 0.6941\n",
            "Epoch 79/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5677 - accuracy: 0.7085\n",
            "Epoch 80/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5743 - accuracy: 0.7071\n",
            "Epoch 81/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5692 - accuracy: 0.7044\n",
            "Epoch 82/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5724 - accuracy: 0.7063\n",
            "Epoch 83/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5773 - accuracy: 0.7009\n",
            "Epoch 84/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5672 - accuracy: 0.7101\n",
            "Epoch 85/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5684 - accuracy: 0.7082\n",
            "Epoch 86/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5635 - accuracy: 0.7139\n",
            "Epoch 87/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5627 - accuracy: 0.7054\n",
            "Epoch 88/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5588 - accuracy: 0.7179\n",
            "Epoch 89/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5604 - accuracy: 0.7064\n",
            "Epoch 90/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5571 - accuracy: 0.7117\n",
            "Epoch 91/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5589 - accuracy: 0.7171\n",
            "Epoch 92/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5510 - accuracy: 0.7225\n",
            "Epoch 93/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5606 - accuracy: 0.7108\n",
            "Epoch 94/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5529 - accuracy: 0.7157\n",
            "Epoch 95/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5532 - accuracy: 0.7146\n",
            "Epoch 96/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5540 - accuracy: 0.7223\n",
            "Epoch 97/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5497 - accuracy: 0.7277\n",
            "Epoch 98/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5493 - accuracy: 0.7284\n",
            "Epoch 99/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5479 - accuracy: 0.7244\n",
            "Epoch 100/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5412 - accuracy: 0.7277\n",
            "Epoch 101/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5367 - accuracy: 0.7362\n",
            "Epoch 102/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5376 - accuracy: 0.7303\n",
            "Epoch 103/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5395 - accuracy: 0.7303\n",
            "Epoch 104/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5476 - accuracy: 0.7213\n",
            "Epoch 105/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5336 - accuracy: 0.7326\n",
            "Epoch 106/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5354 - accuracy: 0.7341\n",
            "Epoch 107/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5424 - accuracy: 0.7406\n",
            "Epoch 108/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5401 - accuracy: 0.7326\n",
            "Epoch 109/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5257 - accuracy: 0.7432\n",
            "Epoch 110/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5280 - accuracy: 0.7347\n",
            "Epoch 111/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5262 - accuracy: 0.7443\n",
            "Epoch 112/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5259 - accuracy: 0.7462\n",
            "Epoch 113/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5284 - accuracy: 0.7359\n",
            "Epoch 114/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5272 - accuracy: 0.7469\n",
            "Epoch 115/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5243 - accuracy: 0.7395\n",
            "Epoch 116/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5251 - accuracy: 0.7415\n",
            "Epoch 117/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5143 - accuracy: 0.7444\n",
            "Epoch 118/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5131 - accuracy: 0.7498\n",
            "Epoch 119/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5154 - accuracy: 0.7467\n",
            "Epoch 120/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5078 - accuracy: 0.7486\n",
            "Epoch 121/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5121 - accuracy: 0.7491\n",
            "Epoch 122/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5058 - accuracy: 0.7568\n",
            "Epoch 123/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5061 - accuracy: 0.7542\n",
            "Epoch 124/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5176 - accuracy: 0.7455\n",
            "Epoch 125/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5025 - accuracy: 0.7524\n",
            "Epoch 126/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5070 - accuracy: 0.7505\n",
            "Epoch 127/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4953 - accuracy: 0.7585\n",
            "Epoch 128/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5027 - accuracy: 0.7610\n",
            "Epoch 129/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.5072 - accuracy: 0.7517\n",
            "Epoch 130/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4930 - accuracy: 0.7627\n",
            "Epoch 131/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4923 - accuracy: 0.7611\n",
            "Epoch 132/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4939 - accuracy: 0.7660\n",
            "Epoch 133/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4879 - accuracy: 0.7667\n",
            "Epoch 134/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4890 - accuracy: 0.7662\n",
            "Epoch 135/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4840 - accuracy: 0.7685\n",
            "Epoch 136/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4842 - accuracy: 0.7603\n",
            "Epoch 137/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4842 - accuracy: 0.7713\n",
            "Epoch 138/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4882 - accuracy: 0.7613\n",
            "Epoch 139/200\n",
            "180/180 [==============================] - 3s 16ms/step - loss: 0.4759 - accuracy: 0.7733\n",
            "Epoch 140/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4815 - accuracy: 0.7716\n",
            "Epoch 141/200\n",
            "180/180 [==============================] - 3s 16ms/step - loss: 0.4826 - accuracy: 0.7699\n",
            "Epoch 142/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4808 - accuracy: 0.7749\n",
            "Epoch 143/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4747 - accuracy: 0.7765\n",
            "Epoch 144/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4705 - accuracy: 0.7794\n",
            "Epoch 145/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4649 - accuracy: 0.7819\n",
            "Epoch 146/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4604 - accuracy: 0.7894\n",
            "Epoch 147/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4590 - accuracy: 0.7838\n",
            "Epoch 148/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4740 - accuracy: 0.7784\n",
            "Epoch 149/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4509 - accuracy: 0.7841\n",
            "Epoch 150/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4598 - accuracy: 0.7834\n",
            "Epoch 151/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4552 - accuracy: 0.7848\n",
            "Epoch 152/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4549 - accuracy: 0.7882\n",
            "Epoch 153/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4476 - accuracy: 0.7911\n",
            "Epoch 154/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4432 - accuracy: 0.7948\n",
            "Epoch 155/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4525 - accuracy: 0.7864\n",
            "Epoch 156/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4403 - accuracy: 0.7930\n",
            "Epoch 157/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4349 - accuracy: 0.7955\n",
            "Epoch 158/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4431 - accuracy: 0.7955\n",
            "Epoch 159/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4359 - accuracy: 0.7965\n",
            "Epoch 160/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4314 - accuracy: 0.8024\n",
            "Epoch 161/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4375 - accuracy: 0.7916\n",
            "Epoch 162/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4334 - accuracy: 0.7908\n",
            "Epoch 163/200\n",
            "180/180 [==============================] - 3s 16ms/step - loss: 0.4326 - accuracy: 0.7979\n",
            "Epoch 164/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4292 - accuracy: 0.7984\n",
            "Epoch 165/200\n",
            "180/180 [==============================] - 3s 16ms/step - loss: 0.4210 - accuracy: 0.8054\n",
            "Epoch 166/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4279 - accuracy: 0.8044\n",
            "Epoch 167/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4162 - accuracy: 0.8105\n",
            "Epoch 168/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4179 - accuracy: 0.8117\n",
            "Epoch 169/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4117 - accuracy: 0.8091\n",
            "Epoch 170/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4078 - accuracy: 0.8073\n",
            "Epoch 171/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4094 - accuracy: 0.8103\n",
            "Epoch 172/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4079 - accuracy: 0.8160\n",
            "Epoch 173/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4117 - accuracy: 0.8084\n",
            "Epoch 174/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.4032 - accuracy: 0.8199\n",
            "Epoch 175/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3991 - accuracy: 0.8195\n",
            "Epoch 176/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3980 - accuracy: 0.8155\n",
            "Epoch 177/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3861 - accuracy: 0.8268\n",
            "Epoch 178/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3968 - accuracy: 0.8164\n",
            "Epoch 179/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3856 - accuracy: 0.8223\n",
            "Epoch 180/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3927 - accuracy: 0.8190\n",
            "Epoch 181/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3884 - accuracy: 0.8237\n",
            "Epoch 182/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3874 - accuracy: 0.8204\n",
            "Epoch 183/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3871 - accuracy: 0.8237\n",
            "Epoch 184/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3743 - accuracy: 0.8300\n",
            "Epoch 185/200\n",
            "180/180 [==============================] - 3s 16ms/step - loss: 0.3711 - accuracy: 0.8312\n",
            "Epoch 186/200\n",
            "180/180 [==============================] - 3s 16ms/step - loss: 0.3729 - accuracy: 0.8315\n",
            "Epoch 187/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3718 - accuracy: 0.8307\n",
            "Epoch 188/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3751 - accuracy: 0.8314\n",
            "Epoch 189/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3696 - accuracy: 0.8326\n",
            "Epoch 190/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3728 - accuracy: 0.8268\n",
            "Epoch 191/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3541 - accuracy: 0.8382\n",
            "Epoch 192/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3645 - accuracy: 0.8364\n",
            "Epoch 193/200\n",
            "180/180 [==============================] - 3s 16ms/step - loss: 0.3609 - accuracy: 0.8343\n",
            "Epoch 194/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3626 - accuracy: 0.8357\n",
            "Epoch 195/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3517 - accuracy: 0.8382\n",
            "Epoch 196/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3608 - accuracy: 0.8382\n",
            "Epoch 197/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3505 - accuracy: 0.8446\n",
            "Epoch 198/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3462 - accuracy: 0.8465\n",
            "Epoch 199/200\n",
            "180/180 [==============================] - 3s 16ms/step - loss: 0.3342 - accuracy: 0.8477\n",
            "Epoch 200/200\n",
            "180/180 [==============================] - 3s 15ms/step - loss: 0.3468 - accuracy: 0.8425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Moi23rvO1e6V"
      },
      "source": [
        "## Save Model to Disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzjA_P67zOzF",
        "outputId": "eb2286d1-3400-48e1-9663-1e4806e25776"
      },
      "source": [
        "model.save('./nn_model')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./nn_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydtiDXA12htl"
      },
      "source": [
        "## Load Model from Disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe28hP0d2Sal"
      },
      "source": [
        "model1 = tf.keras.models.load_model('./nn_model')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CinHtYU23BUM"
      },
      "source": [
        "## Load Training Data from Disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmDnSg7-2s-1"
      },
      "source": [
        "X_test = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/X_test.sav\", \"rb\"))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BciaEQHI5Bb4"
      },
      "source": [
        "X_test = StandardScaler().fit_transform(X_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m3TuPxU5G-0",
        "outputId": "697083d0-48c9-4e00-ae6a-b05ed373d860"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(y_pred) "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0863409 ]\n",
            " [0.12175   ]\n",
            " [0.13569932]\n",
            " ...\n",
            " [0.16165873]\n",
            " [0.8414782 ]\n",
            " [0.77845   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn1BPaST6CiY"
      },
      "source": [
        "y_pred = (y_pred > 0.5).astype('int64')\n",
        "y_pred = y_pred.reshape(len(y_pred)) "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kk48jlG5T6C",
        "outputId": "725fef24-3568-43bd-c2d5-ed7f37ee9537"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq6T1Ps_71EH",
        "outputId": "292504a9-76d4-42af-eb6e-19bcef5b624f"
      },
      "source": [
        "len(y_pred)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1348"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OysgCpf65Xbe"
      },
      "source": [
        "y_test = []\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i] == 0:\n",
        "    y_test.append('NONE')\n",
        "  else:\n",
        "    y_test.append('HOF')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWu63Z_r7jyp",
        "outputId": "ce9888c7-decb-43e1-f0c3-6f9dac6257bb"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'NONE', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NONE', 'HOF', 'NONE', 'HOF', 'HOF']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMWqNFFA8M50"
      },
      "source": [
        "## Loading Test Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2ByNI8X8wrR",
        "outputId": "18f47b2b-8629-4b19-e870-b44f8ccc9621"
      },
      "source": [
        "! git clone https://github.com/bhargav25dave1996/ICHCL_baseline.git\n",
        "% cd /content/drive/MyDrive/Colab Notebooks/ICHCL_baseline"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ICHCL_baseline' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/Colab Notebooks/ICHCL_baseline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa3RWByv9E9K",
        "outputId": "855821dd-b477-4960-afde-ef40a41b01e3"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import re\n",
        "import json\n",
        "\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import stemmer as hindi_stemmer\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnWw1a9k8Eby"
      },
      "source": [
        "english_stopwords = stopwords.words(\"english\")\n",
        "with open('final_stopwords.txt', encoding = 'utf-8') as f:\n",
        "    hindi_stopwords = f.readlines()\n",
        "    for i in range(len(hindi_stopwords)):\n",
        "        hindi_stopwords[i] = re.sub('\\n','',hindi_stopwords[i])\n",
        "stopwords = english_stopwords + hindi_stopwords\n",
        "english_stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jgWJG-A8aGU"
      },
      "source": [
        "test_directories = []\n",
        "for i in glob(\"/content/drive/MyDrive/Colab Notebooks/subtask2_test/*/\"):\n",
        "    for j in glob(i+'*/'):\n",
        "        test_directories.append(j)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drbKyqLe8byd"
      },
      "source": [
        "data = []\n",
        "for i in test_directories:\n",
        "    with open(i+'data.json', encoding='utf-8') as f:\n",
        "        data.append(json.load(f))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KAvc5Ym8ddz"
      },
      "source": [
        "def te_flatten(d):\n",
        "    flat_text = []\n",
        "    flat_text.append({\n",
        "        'tweet_id':d['tweet_id'],\n",
        "        'text':d['tweet'],\n",
        "    })\n",
        "\n",
        "    for i in d['comments']:\n",
        "            flat_text.append({\n",
        "                'tweet_id':i['tweet_id'],\n",
        "                'text':flat_text[0]['text'] + i['tweet'],\n",
        "            })\n",
        "            if 'replies' in i.keys():\n",
        "                for j in i['replies']:\n",
        "                    flat_text.append({\n",
        "                        'tweet_id':j['tweet_id'],\n",
        "                        'text':flat_text[0]['text'] + i['tweet'] + j['tweet'],\n",
        "                    })\n",
        "    return flat_text"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKJ-EljR8fOx"
      },
      "source": [
        "test_tweetid_data = []\n",
        "#for test\n",
        "for i in range(len(data)):\n",
        "    for j in te_flatten(data[i]):\n",
        "        test_tweetid_data.append(j)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdwt99Bx8it6"
      },
      "source": [
        "test_tweetid_data = []\n",
        "#for test\n",
        "for i in range(len(data)):\n",
        "    for j in te_flatten(data[i]):\n",
        "        test_tweetid_data.append(j)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhyfTLzi8oTU"
      },
      "source": [
        "test_df = pd.DataFrame(test_tweetid_data, columns = test_tweetid_data[0].keys(), index = None)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iEPdtzTJ8rIK",
        "outputId": "428a7cfd-8794-4953-a53b-2bbc88030c07"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1392808101007478794</td>\n",
              "      <td>In Gujarat, some believers have been going to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1392808747928539137</td>\n",
              "      <td>In Gujarat, some believers have been going to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1392808849762000898</td>\n",
              "      <td>In Gujarat, some believers have been going to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1392836845361242121</td>\n",
              "      <td>In Gujarat, some believers have been going to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1392900440409337857</td>\n",
              "      <td>In Gujarat, some believers have been going to ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id                                               text\n",
              "0  1392808101007478794  In Gujarat, some believers have been going to ...\n",
              "1  1392808747928539137  In Gujarat, some believers have been going to ...\n",
              "2  1392808849762000898  In Gujarat, some believers have been going to ...\n",
              "3  1392836845361242121  In Gujarat, some believers have been going to ...\n",
              "4  1392900440409337857  In Gujarat, some believers have been going to ..."
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58i1lJyJ-SWc"
      },
      "source": [
        "y_test = np.array(y_test)\n",
        "tweet_id = test_df['tweet_id']\n",
        "tweet_id = np.array(tweet_id)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBpwyEzk-hfs"
      },
      "source": [
        "submission = {'tweet_id': tweet_id, 'label':y_test}\n",
        "submission = pd.DataFrame(submission)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ha97QS9r-igV",
        "outputId": "0bd84f2c-c244-4db6-9640-206389725dd6"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1392808101007478794</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1392808747928539137</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1392808849762000898</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1392836845361242121</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1392900440409337857</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id label\n",
              "0  1392808101007478794  NONE\n",
              "1  1392808747928539137  NONE\n",
              "2  1392808849762000898  NONE\n",
              "3  1392836845361242121  NONE\n",
              "4  1392900440409337857  NONE"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_q35zeX-xhS"
      },
      "source": [
        "submission.to_csv('/content/drive/MyDrive/Colab Notebooks/nn_submission.csv', index = False)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CplS3CdZ-16i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}